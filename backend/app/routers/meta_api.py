from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks, Request
from fastapi.responses import RedirectResponse
from sqlalchemy.orm import Session
from sqlalchemy import func, or_, text
from typing import Optional
from datetime import datetime, timedelta
from ..models.user import User
from ..models.campaign import Campaign, Upload
from ..utils.dependencies import get_current_user
from ..database import get_db
from ..config import settings
import httpx
import urllib.parse
import secrets
import uuid
import json
from decimal import Decimal

router = APIRouter()

async def sync_meta_data_to_campaigns(user: User, access_token: str, account_id: str, db: Session, days: Optional[int] = None):
    """
    Meta APIã‹ã‚‰ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—ã—ã¦Campaignãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
    
    Args:
        user: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        access_token: Meta APIã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³
        account_id: Metaåºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
        db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
        days: å–å¾—ã™ã‚‹æ—¥æ•°ï¼ˆNoneã®å ´åˆã¯37ãƒ¶æœˆã€90ã®å ´åˆã¯3ãƒ¶æœˆãªã©ï¼‰
    """
    # ãƒ€ãƒŸãƒ¼ã®Uploadãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆï¼ˆMeta APIåŒæœŸç”¨ï¼‰
    upload = Upload(
        user_id=user.id,
        file_name="Meta API Sync",
        status="completed",
        row_count=0
    )
    db.add(upload)
    db.flush()  # upload.idã‚’å–å¾—ã™ã‚‹ãŸã‚ã«flush
    
    # JSTï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰ã§æ˜¨æ—¥ã‚’è¨ˆç®—
    from datetime import timezone
    jst = timezone(timedelta(hours=9))  # JST = UTC+9
    current_jst = datetime.now(jst)
    today_jst = current_jst.date()
    yesterday = today_jst - timedelta(days=1)
    
    print(f"[Meta API] Current JST time: {current_jst.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"[Meta API] Today (JST): {today_jst}")
    print(f"[Meta API] Yesterday (JST): {yesterday}")
    
    # æ˜¨æ—¥ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæœªæ¥ã®æ—¥ä»˜ã‚’æŒ‡å®šã™ã‚‹ã¨400ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ï¼‰
    until_dt = yesterday
    until = until_dt.strftime('%Y-%m-%d')
    
    # å–å¾—æœŸé–“ã®æ±ºå®š
    if days is None:
        # å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆMeta APIã®æœ€å¤§ç¯„å›²ï¼šéå»37ãƒ¶æœˆé–“ï¼‰
        # Meta APIã®ä»•æ§˜:
        # - åŸºæœ¬çš„ãªæœ€å¤§å–å¾—æœŸé–“: 37ãƒ¶æœˆï¼ˆ1,095æ—¥ï¼‰
        # - Reach + Breakdownä½¿ç”¨æ™‚: 13ãƒ¶æœˆï¼ˆ394æ—¥ï¼‰ã®ã¿
        # - ç¾åœ¨ã®å®Ÿè£…ã§ã¯Reachãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€Breakdownã¯ä½¿ç”¨ã—ã¦ã„ãªã„ãŸã‚ã€37ãƒ¶æœˆãŒå¯èƒ½
        max_days_total = 1095  # 37ãƒ¶æœˆï¼ˆ1,095æ—¥ï¼‰
        since_dt = until_dt - timedelta(days=max_days_total)
        since = since_dt.strftime('%Y-%m-%d')
        print(f"[Meta API] Full period sync: {since} to {until} (max {max_days_total} days / 37 months)")
        print(f"[Meta API] Date validation: since={since} (year={since_dt.year}), until={until} (year={until_dt.year})")
    else:
        # æŒ‡å®šã•ã‚ŒãŸæ—¥æ•°åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆä¾‹: 90æ—¥ = 3ãƒ¶æœˆï¼‰
        since_dt = until_dt - timedelta(days=days)
        since = since_dt.strftime('%Y-%m-%d')
        print(f"[Meta API] Partial sync: {since} to {until} ({days} days)")
        print(f"[Meta API] Date validation: since={since} (year={since_dt.year}), until={until} (year={until_dt.year})")
        
        # æœªæ¥ã®æ—¥ä»˜ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯è­¦å‘Š
        if since_dt > today_jst or until_dt > today_jst:
            print(f"[Meta API] WARNING: Date range includes future dates! Today (JST): {today_jst}, Since: {since}, Until: {until}")
    
    try:
        async with httpx.AsyncClient() as client:
            all_insights = []
            all_campaigns = []
            
            # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ä¸€è¦§ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
            print(f"[Meta API] Fetching campaigns from account: {account_id}")
            campaigns_url = f"https://graph.facebook.com/v24.0/{account_id}/campaigns"
            campaigns_params = {
                "access_token": access_token,
                "fields": "id,name,status,objective,created_time,updated_time",
                "limit": 100  # Meta APIã®æœ€å¤§å–å¾—ä»¶æ•°
            }
            
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ï¼ˆã™ã¹ã¦ã®campaignsã‚’å–å¾—ï¼‰
            campaigns_page_count = 0
            while True:
                campaigns_page_count += 1
                print(f"[Meta API] Fetching campaigns page {campaigns_page_count}...")
                campaigns_response = await client.get(campaigns_url, params=campaigns_params)
                campaigns_response.raise_for_status()
                campaigns_data = campaigns_response.json()
                
                # å–å¾—ã—ãŸã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’è¿½åŠ 
                page_campaigns = campaigns_data.get('data', [])
                all_campaigns.extend(page_campaigns)
                print(f"[Meta API] Retrieved {len(page_campaigns)} campaigns (total: {len(all_campaigns)})")
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                paging = campaigns_data.get('paging', {})
                next_url = paging.get('next')
                
                if not next_url:
                    # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã¯çµ‚äº†
                    print(f"[Meta API] No more campaign pages. Total campaigns retrieved: {len(all_campaigns)}")
                    break
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ã®URLã‚’è¨­å®šï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ï¼‰
                campaigns_url = next_url
                campaigns_params = {}  # URLã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã‚¯ãƒªã‚¢
            
            print(f"[Meta API] Total campaigns fetched: {len(all_campaigns)}")
            
            # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³IDã‹ã‚‰ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³åã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
            campaign_id_to_name_map = {}
            for campaign in all_campaigns:
                campaign_id = campaign['id']
                campaign_name = campaign.get('name', 'Unknown')
                campaign_id_to_name_map[campaign_id] = campaign_name
            
            print(f"[Meta API] Created campaign-id-to-name mapping: {len(campaign_id_to_name_map)} campaigns")
            
            # å„ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®Insightsã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰
            print(f"[Meta API] Processing {len(all_campaigns)} campaigns for campaign-level insights...")
            
            # æ—¥ä»˜ç¯„å›²ã®æ±ºå®š: days=Noneã®å ´åˆã¯æ—¢ã«è¨­å®šã•ã‚ŒãŸsince/untilã‚’ä½¿ç”¨
            # daysãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã€current_untilã‚’å†è¨ˆç®—
            if days is None:
                # å…¨æœŸé–“å–å¾—: æ—¢ã«è¨­å®šã•ã‚ŒãŸsince/untilã‚’ä½¿ç”¨
                current_since = datetime.strptime(since, '%Y-%m-%d')
                current_until = datetime.strptime(until, '%Y-%m-%d')
                print(f"[Meta API] Full period sync: Using pre-calculated date range (days=None)")
            else:
                # éƒ¨åˆ†å–å¾—: æ˜¨æ—¥ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆJSTã‚’ä½¿ç”¨ã—ã¦æœªæ¥ã®æ—¥ä»˜ã‚’é¿ã‘ã‚‹ï¼‰
                current_until = yesterday
                current_since = datetime.strptime(since, '%Y-%m-%d')
            
            # Meta APIã®æœŸé–“åˆ¶é™ã‚’ç¢ºèª
            # - Reachãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€Breakdownã¯ä½¿ç”¨ã—ã¦ã„ãªã„ãŸã‚ã€37ãƒ¶æœˆï¼ˆ1,095æ—¥ï¼‰ãŒå¯èƒ½
            campaign_fields = "campaign_id,campaign_name,date_start,spend,impressions,clicks,inline_link_clicks,reach,actions,conversions,action_values,frequency"
            has_reach = "reach" in campaign_fields.lower()
            has_breakdowns = False  # ç¾åœ¨ã®å®Ÿè£…ã§ã¯breakdownsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„
            
            if has_reach and has_breakdowns:
                # Reach + Breakdownã®å ´åˆã¯13ãƒ¶æœˆåˆ¶é™
                max_days_total = 394  # 13ãƒ¶æœˆ
                print(f"[Meta API] Reach with breakdowns detected - limiting to 13 months ({max_days_total} days)")
            else:
                # ãã‚Œä»¥å¤–ã¯37ãƒ¶æœˆ
                max_days_total = 1095  # 37ãƒ¶æœˆ
                print(f"[Meta API] Standard limit - 37 months ({max_days_total} days)")
                print(f"[Meta API] Fields requested: {campaign_fields}")
                print(f"[Meta API] Has reach: {has_reach}, Has breakdowns: {has_breakdowns}")
            
            # ç·æœŸé–“ã‚’åˆ¶é™ï¼ˆ37ãƒ¶æœˆã¾ãŸã¯13ãƒ¶æœˆï¼‰
            # days=Noneï¼ˆå…¨æœŸé–“å–å¾—ï¼‰ã®å ´åˆã¯ã€æ—¢ã«æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚åˆ¶é™ä¸è¦
            # daysãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿åˆ¶é™ã‚’é©ç”¨
            if days is not None and (current_until - current_since).days > max_days_total:
                current_since = current_until - timedelta(days=max_days_total)
                print(f"[Meta API] Date range limited to {max_days_total} days: {current_since.strftime('%Y-%m-%d')} to {current_until.strftime('%Y-%m-%d')}")
            elif days is None:
                actual_days = (current_until - current_since).days
                print(f"[Meta API] Full period sync: Using full {actual_days} days range (days=None, since={since}, until={until})")
            
            # æ—¥ä»˜ç¯„å›²ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            start_date_str = current_since.strftime('%Y-%m-%d')
            end_date_str = current_until.strftime('%Y-%m-%d')
            actual_days = (current_until - current_since).days
            print(f"[Meta API] Final date range: {start_date_str} to {end_date_str} ({actual_days} days)")
            
            # ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«Insightsã‚’å–å¾—ï¼ˆæœ€å¤§50ä»¶/ãƒãƒƒãƒï¼‰
            campaign_fields = "campaign_id,campaign_name,date_start,spend,impressions,clicks,inline_link_clicks,reach,actions,conversions,action_values,frequency"
            time_range_dict = {
                "since": start_date_str,
                "until": end_date_str
            }
            time_range_json = json.dumps(time_range_dict, separators=(',', ':'))  # ã‚¹ãƒšãƒ¼ã‚¹ãªã—JSON
            # time_increment=1ã‚’è¿½åŠ ã—ã¦æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé‡è¦ï¼šã“ã‚ŒãŒãªã„ã¨æœŸé–“å…¨ä½“ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã ã‘è¿”ã•ã‚Œã‚‹ï¼‰
            time_increment = "1"
            
            # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã‚’50ä»¶ãšã¤ã®ãƒãƒƒãƒã«åˆ†å‰²
            batch_size = 50  # Meta APIã®ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ€å¤§æ•°
            for batch_start in range(0, len(all_campaigns), batch_size):
                batch_end = min(batch_start + batch_size, len(all_campaigns))
                batch_campaigns = all_campaigns[batch_start:batch_end]
                batch_num = (batch_start // batch_size) + 1
                total_batches = (len(all_campaigns) + batch_size - 1) // batch_size
                
                print(f"[Meta API] Processing campaign batch {batch_num}/{total_batches} ({len(batch_campaigns)} campaigns)")
                
                # ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆ
                batch_requests = []
                for campaign in batch_campaigns:
                    campaign_id = campaign.get('id')
                    # ç›¸å¯¾URLã‚’ä½œæˆï¼ˆaccess_tokenã¨time_rangeã‚’å«ã‚€ï¼‰
                    # time_increment=1ã‚’è¿½åŠ ã—ã¦æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé‡è¦ï¼šã“ã‚ŒãŒãªã„ã¨æœŸé–“å…¨ä½“ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿ãŒ1ä»¶ã ã‘è¿”ã•ã‚Œã‚‹ï¼‰
                    # Meta APIã®ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã¯ã€time_rangeã¯JSONæ–‡å­—åˆ—ã¨ã—ã¦æ¸¡ã™å¿…è¦ãŒã‚ã‚‹
                    # URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ã ãŒã€{}ã‚„:ãªã©ã®æ–‡å­—ã‚‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
                    # time_rangeã¯{"since":"2022-11-26","until":"2025-12-22"}ã®å½¢å¼
                    time_range_encoded = urllib.parse.quote(time_range_json, safe='')
                    # time_incrementãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆæ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«å¿…é ˆï¼‰
                    relative_url = f"{campaign_id}/insights?fields={campaign_fields}&time_range={time_range_encoded}&time_increment={time_increment}&limit=100"
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®ãƒãƒƒãƒã®æœ€åˆã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ã¿ï¼‰
                    if batch_start == 0 and len(batch_requests) == 0:
                        print(f"[Meta API] Sample relative_url for batch request: {relative_url}")
                        print(f"[Meta API] time_range_json: {time_range_json}")
                        print(f"[Meta API] time_range_encoded: {time_range_encoded}")
                        print(f"[Meta API] time_increment: {time_increment}")
                        print(f"[Meta API] Full URL would be: https://graph.facebook.com/v24.0/{relative_url}")
                    
                    batch_requests.append({
                        "method": "GET",
                        "relative_url": relative_url
                    })
                
                try:
                    # ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
                    batch_url = "https://graph.facebook.com/v24.0/"
                    batch_params = {
                        "access_token": access_token,
                        "batch": json.dumps(batch_requests, separators=(',', ':'))
                    }
                    
                    # ãƒ‡ãƒãƒƒã‚°: ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å†…å®¹ã‚’ç¢ºèªï¼ˆæœ€åˆã®ãƒãƒƒãƒã®ã¿ï¼‰
                    if batch_start == 0:
                        print(f"[Meta API] ===== Batch Request Debug (First Batch) =====")
                        print(f"[Meta API] Batch URL: {batch_url}")
                        print(f"[Meta API] Number of requests in batch: {len(batch_requests)}")
                        print(f"[Meta API] First request relative_url: {batch_requests[0].get('relative_url')}")
                        print(f"[Meta API] First request method: {batch_requests[0].get('method')}")
                        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆURLã‚’è§£æã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºèª
                        first_relative_url = batch_requests[0].get('relative_url', '')
                        print(f"[Meta API] Parsed relative_url: {first_relative_url}")
                        # time_rangeã¨time_incrementãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                        if 'time_range=' in first_relative_url:
                            print(f"[Meta API] âœ“ time_range parameter found in URL")
                        else:
                            print(f"[Meta API] âœ— ERROR: time_range parameter NOT found in URL!")
                        if 'time_increment=' in first_relative_url:
                            print(f"[Meta API] âœ“ time_increment parameter found in URL")
                        else:
                            print(f"[Meta API] âœ— ERROR: time_increment parameter NOT found in URL!")
                        print(f"[Meta API] ==============================================")
                    
                    batch_response = await client.post(batch_url, params=batch_params)
                    batch_response.raise_for_status()
                    batch_data = batch_response.json()
                    
                    # ãƒ‡ãƒãƒƒã‚°: ãƒãƒƒãƒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å†…å®¹ã‚’ç¢ºèªï¼ˆæœ€åˆã®ãƒãƒƒãƒã®æœ€åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã¿ï¼‰
                    if batch_start == 0 and len(batch_data) > 0:
                        first_response = batch_data[0]
                        print(f"[Meta API] ===== Batch Response Debug (First Response) =====")
                        print(f"[Meta API] Response code: {first_response.get('code')}")
                        if first_response.get('code') == 200:
                            try:
                                first_body = json.loads(first_response.get('body', '{}'))
                                first_data = first_body.get('data', [])
                                print(f"[Meta API] Total insights in first response: {len(first_data)}")
                                if len(first_data) > 0:
                                    print(f"[Meta API] First insight date_start: {first_data[0].get('date_start')}")
                                    print(f"[Meta API] First insight campaign_name: {first_data[0].get('campaign_name')}")
                                    if len(first_data) > 1:
                                        print(f"[Meta API] Second insight date_start: {first_data[1].get('date_start')}")
                                        dates_in_first_batch = [d.get('date_start') for d in first_data[:10] if d.get('date_start')]
                                        unique_dates_in_batch = sorted(list(set(dates_in_first_batch)))
                                        print(f"[Meta API] First 10 dates in batch: {dates_in_first_batch}")
                                        print(f"[Meta API] Unique dates in first 10 insights: {unique_dates_in_batch}")
                                        print(f"[Meta API] Number of unique dates: {len(unique_dates_in_batch)}")
                                        if len(unique_dates_in_batch) == 1:
                                            print(f"[Meta API] âš ï¸ WARNING: Only 1 unique date in first 10 insights!")
                                    else:
                                        print(f"[Meta API] âš ï¸ WARNING: Only 1 insight returned!")
                                else:
                                    print(f"[Meta API] âš ï¸ WARNING: No insights in response!")
                                    print(f"[Meta API] Response body: {first_response.get('body', '')[:500]}")
                            except Exception as e:
                                print(f"[Meta API] Error parsing first response: {str(e)}")
                                print(f"[Meta API] Response body: {first_response.get('body', '')[:500]}")
                        else:
                            print(f"[Meta API] âœ— ERROR: Response code is not 200!")
                            print(f"[Meta API] Response body: {first_response.get('body', '')[:500]}")
                        print(f"[Meta API] ================================================")
                    
                    # ãƒãƒƒãƒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
                    for idx, batch_item in enumerate(batch_data):
                        campaign = batch_campaigns[idx]
                        campaign_name = campaign.get('name', 'Unknown')
                        campaign_id = campaign.get('id')
                        
                        if batch_item.get('code') == 200:
                            try:
                                item_body = json.loads(batch_item.get('body', '{}'))
                                page_insights = item_body.get('data', [])
                                
                                if len(page_insights) > 0:
                                    all_insights.extend(page_insights)
                                    
                                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®ãƒãƒƒãƒã®æœ€åˆã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ã¿ï¼‰
                                    if batch_start == 0 and idx == 0:
                                        sample = page_insights[0]
                                        print(f"[Meta API] Sample insight data for campaign {campaign_name}:")
                                        print(f"  date_start: {sample.get('date_start')}")
                                        print(f"  impressions: {sample.get('impressions')}")
                                        print(f"  clicks: {sample.get('clicks')}")
                                        print(f"  inline_link_clicks: {sample.get('inline_link_clicks')}")
                                        print(f"  spend: {sample.get('spend')}")
                                        print(f"  reach: {sample.get('reach')}")
                                        print(f"  frequency: {sample.get('frequency')}")
                                        print(f"  Total insights retrieved: {len(page_insights)}")
                                        # æ—¥ä»˜ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª
                                        if len(page_insights) > 1:
                                            dates = [insight.get('date_start') for insight in page_insights[:10] if insight.get('date_start')]
                                            unique_dates = list(set(dates))
                                            print(f"  Sample dates (first 10 insights): {unique_dates}")
                                            print(f"  Unique dates count: {len(unique_dates)}")
                                    
                                    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ï¼ˆpagingãŒã‚ã‚‹å ´åˆï¼‰
                                    paging = item_body.get('paging', {})
                                    page_count = 1
                                    while 'next' in paging:
                                        page_count += 1
                                        next_url = paging['next']
                                        # next_urlã«ã¯æ—¢ã«access_tokenãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãã®ã¾ã¾ä½¿ç”¨
                                        print(f"[Meta API] Fetching page {page_count} for {campaign_name}...")
                                        next_response = await client.get(next_url)
                                        next_response.raise_for_status()
                                        next_data = next_response.json()
                                        next_insights = next_data.get('data', [])
                                        all_insights.extend(next_insights)
                                        paging = next_data.get('paging', {})
                                        print(f"[Meta API] Retrieved {len(next_insights)} more insights for {campaign_name} (page {page_count}, total: {len(all_insights)})")
                                        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒãƒƒã‚°ï¼ˆæœ€åˆã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ã¿ï¼‰
                                        if batch_start == 0 and idx == 0 and len(next_insights) > 0:
                                            next_dates = [d.get('date_start') for d in next_insights[:5] if d.get('date_start')]
                                            print(f"[Meta API] Sample dates from page {page_count}: {next_dates}")
                                    if page_count > 1:
                                        print(f"[Meta API] Completed pagination for {campaign_name}: {page_count} pages, {len([i for i in all_insights if i.get('campaign_name') == campaign_name])} total insights")
                                    
                                    if idx < 3 or (batch_start == 0 and idx == 0):
                                        print(f"  âœ“ Success: Retrieved {len(page_insights)} insights for {campaign_name}")
                                else:
                                    if idx < 3:
                                        print(f"  âš  No insights data returned for {campaign_name}")
                            except json.JSONDecodeError as e:
                                print(f"[Meta API] Error parsing batch response for {campaign_name}: {str(e)}")
                                print(f"  Response body: {batch_item.get('body', '')[:200]}")
                        else:
                            error_body = batch_item.get('body', '{}')
                            try:
                                error_data = json.loads(error_body) if isinstance(error_body, str) else error_body
                                error_msg = error_data.get('error', {}).get('message', str(error_body))
                                print(f"[Meta API] Error fetching insights for {campaign_name} ({campaign_id}): {error_msg}")
                            except:
                                print(f"[Meta API] Error fetching insights for {campaign_name} ({campaign_id}): {error_body}")
                
                except Exception as e:
                    print(f"[Meta API] Error processing campaign batch {batch_num}: {str(e)}")
                    # ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚æ¬¡ã®ãƒãƒƒãƒã®å‡¦ç†ã‚’ç¶šè¡Œ
                    continue
            
            print(f"[Meta API] Campaign-level insights retrieved: {len(all_insights)}")
            
            # ===== æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰ =====
            # 7æ—¥é–“ã€30æ—¥é–“ã€å…¨æœŸé–“ã®3ã¤ã®æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’å–å¾—
            print(f"[Meta API] Fetching period unique reach for campaign-level data (7days, 30days, all)...")
            campaign_period_reach_7days_map = {}  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å -> 7æ—¥é–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°
            campaign_period_reach_30days_map = {}  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å -> 30æ—¥é–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°
            campaign_period_reach_all_map = {}  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å -> å…¨æœŸé–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°
            
            # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ï¼ˆad_set_nameã¨ad_nameãŒç©ºã®ãƒ‡ãƒ¼ã‚¿ï¼‰
            campaign_level_campaigns = [c for c in all_campaigns]
            
            # æœŸé–“åˆ¥ã®time_rangeã‚’è¨ˆç®—
            # æ˜¨æ—¥ã¾ã§ã®æ—¥ä»˜ã‚’ä½¿ç”¨
            yesterday_dt = until_dt
            yesterday_str = yesterday_dt.strftime('%Y-%m-%d')
            
            # 7æ—¥é–“: æ˜¨æ—¥ã‹ã‚‰6æ—¥å‰ã¾ã§
            seven_days_ago_dt = yesterday_dt - timedelta(days=6)
            seven_days_ago_str = seven_days_ago_dt.strftime('%Y-%m-%d')
            time_range_7days_json = json.dumps({"since": seven_days_ago_str, "until": yesterday_str}, separators=(',', ':'))
            time_range_7days_encoded = urllib.parse.quote(time_range_7days_json, safe='')
            
            # 30æ—¥é–“: æ˜¨æ—¥ã‹ã‚‰29æ—¥å‰ã¾ã§
            thirty_days_ago_dt = yesterday_dt - timedelta(days=29)
            thirty_days_ago_str = thirty_days_ago_dt.strftime('%Y-%m-%d')
            time_range_30days_json = json.dumps({"since": thirty_days_ago_str, "until": yesterday_str}, separators=(',', ':'))
            time_range_30days_encoded = urllib.parse.quote(time_range_30days_json, safe='')
            
            # å…¨æœŸé–“: æ—¢å­˜ã®time_rangeã‚’ä½¿ç”¨
            # time_range_encodedã¯æ—¢ã«è¨ˆç®—æ¸ˆã¿
            
            # time_rangeã®æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆå…¨æœŸé–“ã®å ´åˆï¼‰
            print(f"[Meta API] ğŸ” DEBUG: Time range for 'all' period:")
            print(f"[Meta API]   time_range_dict: {time_range_dict}")
            print(f"[Meta API]   time_range_json: {time_range_json}")
            print(f"[Meta API]   time_range_encoded: {time_range_encoded}")
            print(f"[Meta API]   start_date_str: {start_date_str}")
            print(f"[Meta API]   end_date_str: {end_date_str}")
            
            # æœŸé–“åˆ¥ã®ãƒãƒƒãƒ—ã¨time_rangeã®ãƒšã‚¢
            period_configs = [
                ("7days", campaign_period_reach_7days_map, time_range_7days_encoded),
                ("30days", campaign_period_reach_30days_map, time_range_30days_encoded),
                ("all", campaign_period_reach_all_map, time_range_encoded)
            ]
            
            # å„æœŸé–“ã«ã¤ã„ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’å–å¾—
            for period_name, period_map, period_time_range_encoded in period_configs:
                print(f"[Meta API] Fetching {period_name} unique reach for campaign-level data...")
                
                for batch_start in range(0, len(campaign_level_campaigns), batch_size):
                    batch_end = min(batch_start + batch_size, len(campaign_level_campaigns))
                    batch_campaigns = campaign_level_campaigns[batch_start:batch_end]
                    batch_num = (batch_start // batch_size) + 1
                    total_batches = (len(campaign_level_campaigns) + batch_size - 1) // batch_size
                    
                    print(f"[Meta API] Processing {period_name} unique reach batch {batch_num}/{total_batches} ({len(batch_campaigns)} campaigns)")
                    
                    batch_requests = []
                    for campaign in batch_campaigns:
                        campaign_id = campaign.get('id')
                        campaign_name_check = campaign.get('name', 'Unknown')
                        # æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—ï¼ˆtime_incrementãªã—ï¼‰
                        period_reach_fields = "campaign_id,campaign_name,reach"
                        relative_url = f"{campaign_id}/insights?fields={period_reach_fields}&time_range={period_time_range_encoded}&level=campaign&limit=100"
                        
                        # ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å ´åˆã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆURLã‚’ãƒ­ã‚°å‡ºåŠ›
                        if 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°' in campaign_name_check and period_name == 'all':
                            print(f"[Meta API] ğŸ” DEBUG: Request URL for {campaign_name_check} ({period_name}):")
                            print(f"[Meta API]   Campaign ID: {campaign_id}")
                            print(f"[Meta API]   Time Range Encoded: {period_time_range_encoded}")
                            print(f"[Meta API]   Relative URL: {relative_url}")
                        
                        batch_requests.append({
                            "method": "GET",
                            "relative_url": relative_url
                        })
                    
                    try:
                        # ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
                        period_batch_params = {
                            "access_token": access_token,
                            "batch": json.dumps(batch_requests, separators=(',', ':'))
                        }
                        batch_response = await client.post(batch_url, params=period_batch_params)
                        batch_response.raise_for_status()
                        batch_data = batch_response.json()
                        
                        for idx, batch_item in enumerate(batch_data):
                            campaign = batch_campaigns[idx]
                            campaign_name = campaign.get('name', 'Unknown')
                            campaign_id = campaign.get('id')
                            
                            if batch_item.get('code') == 200:
                                try:
                                    item_body = json.loads(batch_item.get('body', '{}'))
                                    period_insights = item_body.get('data', [])
                                    
                                    if len(period_insights) > 0:
                                        # æœŸé–“å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã¯1ä»¶ã®ã¿ï¼ˆtime_incrementãªã—ã®å ´åˆï¼‰
                                        insight_data = period_insights[0]
                                        period_reach = safe_int(insight_data.get('reach'), 0)
                                        period_map[campaign_name] = period_reach
                                        print(f"[Meta API] {period_name} unique reach for {campaign_name}: {period_reach:,}")
                                        
                                        # ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å ´åˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
                                        if 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°' in campaign_name and period_name == 'all':
                                            print(f"[Meta API] ğŸ” DEBUG: Full response data for {campaign_name} ({period_name}):")
                                            print(f"[Meta API]   Raw insight_data: {json.dumps(insight_data, indent=2, ensure_ascii=False)}")
                                            print(f"[Meta API]   Reach value (raw): {insight_data.get('reach')}")
                                            print(f"[Meta API]   Reach value (parsed): {period_reach:,}")
                                            print(f"[Meta API]   Campaign ID: {insight_data.get('campaign_id')}")
                                            print(f"[Meta API]   Campaign Name: {insight_data.get('campaign_name')}")
                                            print(f"[Meta API]   All keys in insight_data: {list(insight_data.keys())}")
                                    else:
                                        print(f"[Meta API] âš ï¸ No {period_name} reach data for {campaign_name}")
                                        # ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å ´åˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’ãƒ­ã‚°å‡ºåŠ›
                                        if 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°' in campaign_name and period_name == 'all':
                                            print(f"[Meta API] ğŸ” DEBUG: Empty response for {campaign_name} ({period_name}):")
                                            print(f"[Meta API]   Response body: {json.dumps(item_body, indent=2, ensure_ascii=False)}")
                                except json.JSONDecodeError as e:
                                    print(f"[Meta API] Error parsing {period_name} reach response for {campaign_name}: {str(e)}")
                            else:
                                error_body = batch_item.get('body', '{}')
                                try:
                                    error_data = json.loads(error_body) if isinstance(error_body, str) else error_body
                                    error_msg = error_data.get('error', {}).get('message', str(error_body))
                                    print(f"[Meta API] Error fetching {period_name} reach for {campaign_name} ({campaign_id}): {error_msg}")
                                except:
                                    print(f"[Meta API] Error fetching {period_name} reach for {campaign_name} ({campaign_id}): {error_body}")
                    
                    except Exception as e:
                        print(f"[Meta API] Error processing {period_name} reach batch {batch_num}: {str(e)}")
                        continue
                
                print(f"[Meta API] {period_name} unique reach retrieved for {len(period_map)} campaigns")
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å…¨æœŸé–“ã®å€¤ã‚’period_unique_reachã«ã‚‚è¨­å®š
            campaign_period_reach_map = campaign_period_reach_all_map.copy()
            
            # ===== åºƒå‘Šã‚»ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã®insightså–å¾— =====
            print(f"[Meta API] Fetching adset-level insights for account {account_id}...")
            adset_fields = "campaign_id,campaign_name,adset_name,date_start,spend,impressions,clicks,inline_link_clicks,reach,actions,conversions,action_values,frequency"
            all_adset_insights = []
            
            for batch_start in range(0, len(all_campaigns), batch_size):
                batch_end = min(batch_start + batch_size, len(all_campaigns))
                batch_campaigns = all_campaigns[batch_start:batch_end]
                batch_num = (batch_start // batch_size) + 1
                total_batches = (len(all_campaigns) + batch_size - 1) // batch_size
                
                print(f"[Meta API] Processing adset-level batch {batch_num}/{total_batches} ({len(batch_campaigns)} campaigns)")
                
                batch_requests = []
                for campaign in batch_campaigns:
                    campaign_id = campaign.get('id')
                    # åºƒå‘Šã‚»ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã®insightsã‚’å–å¾—
                    relative_url = f"{campaign_id}/insights?level=adset&fields={adset_fields}&time_range={time_range_encoded}&time_increment={time_increment}&limit=100"
                    batch_requests.append({
                        "method": "GET",
                        "relative_url": relative_url
                    })
                
                try:
                    batch_response = await client.post(batch_url, params=batch_params)
                    batch_response.raise_for_status()
                    batch_data = batch_response.json()
                    
                    for idx, batch_item in enumerate(batch_data):
                        campaign = batch_campaigns[idx]
                        campaign_name = campaign.get('name', 'Unknown')
                        campaign_id = campaign.get('id')
                        
                        if batch_item.get('code') == 200:
                            try:
                                item_body = json.loads(batch_item.get('body', '{}'))
                                page_insights = item_body.get('data', [])
                                
                                if len(page_insights) > 0:
                                    all_adset_insights.extend(page_insights)
                                    
                                    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†
                                    paging = item_body.get('paging', {})
                                    page_count = 1
                                    while 'next' in paging:
                                        page_count += 1
                                        next_url = paging['next']
                                        next_response = await client.get(next_url)
                                        next_response.raise_for_status()
                                        next_data = next_response.json()
                                        next_insights = next_data.get('data', [])
                                        all_adset_insights.extend(next_insights)
                                        paging = next_data.get('paging', {})
                                        print(f"[Meta API] Retrieved {len(next_insights)} more adset insights for {campaign_name} (page {page_count}, total: {len(all_adset_insights)})")
                            except json.JSONDecodeError as e:
                                print(f"[Meta API] Error parsing adset batch response for {campaign_name}: {str(e)}")
                        else:
                            error_body = batch_item.get('body', '{}')
                            try:
                                error_data = json.loads(error_body) if isinstance(error_body, str) else error_body
                                error_msg = error_data.get('error', {}).get('message', str(error_body))
                                print(f"[Meta API] Error fetching adset insights for {campaign_name} ({campaign_id}): {error_msg}")
                            except:
                                print(f"[Meta API] Error fetching adset insights for {campaign_name} ({campaign_id}): {error_body}")
                
                except Exception as e:
                    print(f"[Meta API] Error processing adset batch {batch_num}: {str(e)}")
                    continue
            
            print(f"[Meta API] Adset-level insights retrieved: {len(all_adset_insights)}")
            
            # ===== åºƒå‘Šãƒ¬ãƒ™ãƒ«ã®insightså–å¾— =====
            print(f"[Meta API] Fetching ad-level insights for account {account_id}...")
            ad_fields = "campaign_id,campaign_name,adset_name,ad_name,date_start,spend,impressions,clicks,inline_link_clicks,reach,actions,conversions,action_values,frequency"
            all_ad_insights = []
            
            for batch_start in range(0, len(all_campaigns), batch_size):
                batch_end = min(batch_start + batch_size, len(all_campaigns))
                batch_campaigns = all_campaigns[batch_start:batch_end]
                batch_num = (batch_start // batch_size) + 1
                total_batches = (len(all_campaigns) + batch_size - 1) // batch_size
                
                print(f"[Meta API] Processing ad-level batch {batch_num}/{total_batches} ({len(batch_campaigns)} campaigns)")
                
                batch_requests = []
                for campaign in batch_campaigns:
                    campaign_id = campaign.get('id')
                    # åºƒå‘Šãƒ¬ãƒ™ãƒ«ã®insightsã‚’å–å¾—
                    relative_url = f"{campaign_id}/insights?level=ad&fields={ad_fields}&time_range={time_range_encoded}&time_increment={time_increment}&limit=100"
                    batch_requests.append({
                        "method": "GET",
                        "relative_url": relative_url
                    })
                
                try:
                    batch_response = await client.post(batch_url, params=batch_params)
                    batch_response.raise_for_status()
                    batch_data = batch_response.json()
                    
                    for idx, batch_item in enumerate(batch_data):
                        campaign = batch_campaigns[idx]
                        campaign_name = campaign.get('name', 'Unknown')
                        campaign_id = campaign.get('id')
                        
                        if batch_item.get('code') == 200:
                            try:
                                item_body = json.loads(batch_item.get('body', '{}'))
                                page_insights = item_body.get('data', [])
                                
                                if len(page_insights) > 0:
                                    all_ad_insights.extend(page_insights)
                                    
                                    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†
                                    paging = item_body.get('paging', {})
                                    page_count = 1
                                    while 'next' in paging:
                                        page_count += 1
                                        next_url = paging['next']
                                        next_response = await client.get(next_url)
                                        next_response.raise_for_status()
                                        next_data = next_response.json()
                                        next_insights = next_data.get('data', [])
                                        all_ad_insights.extend(next_insights)
                                        paging = next_data.get('paging', {})
                                        print(f"[Meta API] Retrieved {len(next_insights)} more ad insights for {campaign_name} (page {page_count}, total: {len(all_ad_insights)})")
                            except json.JSONDecodeError as e:
                                print(f"[Meta API] Error parsing ad batch response for {campaign_name}: {str(e)}")
                        else:
                            error_body = batch_item.get('body', '{}')
                            try:
                                error_data = json.loads(error_body) if isinstance(error_body, str) else error_body
                                error_msg = error_data.get('error', {}).get('message', str(error_body))
                                print(f"[Meta API] Error fetching ad insights for {campaign_name} ({campaign_id}): {error_msg}")
                            except:
                                print(f"[Meta API] Error fetching ad insights for {campaign_name} ({campaign_id}): {error_body}")
                
                except Exception as e:
                    print(f"[Meta API] Error processing ad batch {batch_num}: {str(e)}")
                    continue
            
            print(f"[Meta API] Ad-level insights retrieved: {len(all_ad_insights)}")
            
            # ã™ã¹ã¦ã®ãƒ¬ãƒ™ãƒ«ã®insightsã‚’çµ±åˆ
            all_insights = all_insights + all_adset_insights + all_ad_insights
            print(f"[Meta API] Total insights (all levels): {len(all_insights)} (campaign: {len(all_insights) - len(all_adset_insights) - len(all_ad_insights)}, adset: {len(all_adset_insights)}, ad: {len(all_ad_insights)})")
            
            # æ•°å€¤ã®å®‰å…¨ãªãƒ‘ãƒ¼ã‚¹é–¢æ•°ï¼ˆNoneã‚„ç©ºæ–‡å­—åˆ—ã‚’0ã«å¤‰æ›ï¼‰
            def safe_float(value, default=0.0):
                if value is None or value == '':
                    return default
                try:
                    return float(value)
                except (ValueError, TypeError):
                    return default
            
            def safe_int(value, default=0):
                if value is None or value == '':
                    return default
                try:
                    return int(float(value))  # floatçµŒç”±ã§å¤‰æ›ï¼ˆæ–‡å­—åˆ—ã®æ•°å€¤ã‚‚å¯¾å¿œï¼‰
                except (ValueError, TypeError):
                    return default
            
            # ===== æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰ =====
            # 7æ—¥é–“ã€30æ—¥é–“ã€å…¨æœŸé–“ã®3ã¤ã®æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’å–å¾—
            print(f"[Meta API] Fetching period unique reach for campaign-level data (7days, 30days, all)...")
            campaign_period_reach_7days_map = {}  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å -> 7æ—¥é–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°
            campaign_period_reach_30days_map = {}  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å -> 30æ—¥é–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°
            campaign_period_reach_all_map = {}  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å -> å…¨æœŸé–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°
            
            # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ï¼ˆad_set_nameã¨ad_nameãŒç©ºã®ãƒ‡ãƒ¼ã‚¿ï¼‰
            # all_campaignsã‹ã‚‰ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³IDã¨åå‰ã‚’å–å¾—
            campaign_level_campaigns = [c for c in all_campaigns]
            
            # æœŸé–“åˆ¥ã®time_rangeã‚’è¨ˆç®—
            # æ˜¨æ—¥ã¾ã§ã®æ—¥ä»˜ã‚’ä½¿ç”¨
            yesterday_dt = until_dt
            yesterday_str = yesterday_dt.strftime('%Y-%m-%d')
            
            # 7æ—¥é–“: æ˜¨æ—¥ã‹ã‚‰6æ—¥å‰ã¾ã§
            seven_days_ago_dt = yesterday_dt - timedelta(days=6)
            seven_days_ago_str = seven_days_ago_dt.strftime('%Y-%m-%d')
            time_range_7days_json = json.dumps({"since": seven_days_ago_str, "until": yesterday_str}, separators=(',', ':'))
            time_range_7days_encoded = urllib.parse.quote(time_range_7days_json, safe='')
            
            # 30æ—¥é–“: æ˜¨æ—¥ã‹ã‚‰29æ—¥å‰ã¾ã§
            thirty_days_ago_dt = yesterday_dt - timedelta(days=29)
            thirty_days_ago_str = thirty_days_ago_dt.strftime('%Y-%m-%d')
            time_range_30days_json = json.dumps({"since": thirty_days_ago_str, "until": yesterday_str}, separators=(',', ':'))
            time_range_30days_encoded = urllib.parse.quote(time_range_30days_json, safe='')
            
            # å…¨æœŸé–“: æ—¢å­˜ã®time_rangeã‚’ä½¿ç”¨
            time_range_encoded = urllib.parse.quote(time_range_json, safe='')
            
            # time_rangeã®æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆå…¨æœŸé–“ã®å ´åˆï¼‰
            print(f"[Meta API] ğŸ” DEBUG: Time range for 'all' period (second location):")
            print(f"[Meta API]   time_range_dict: {time_range_dict}")
            print(f"[Meta API]   time_range_json: {time_range_json}")
            print(f"[Meta API]   time_range_encoded: {time_range_encoded}")
            print(f"[Meta API]   start_date_str: {start_date_str}")
            print(f"[Meta API]   end_date_str: {end_date_str}")
            
            # æœŸé–“åˆ¥ã®ãƒãƒƒãƒ—ã¨time_rangeã®ãƒšã‚¢
            period_configs = [
                ("7days", campaign_period_reach_7days_map, time_range_7days_encoded),
                ("30days", campaign_period_reach_30days_map, time_range_30days_encoded),
                ("all", campaign_period_reach_all_map, time_range_encoded)
            ]
            
            if len(campaign_level_campaigns) > 0:
                # å„æœŸé–“ã«ã¤ã„ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’å–å¾—
                for period_name, period_map, period_time_range_encoded in period_configs:
                    print(f"[Meta API] Fetching {period_name} unique reach for campaign-level data...")
                    
                    # ãƒãƒƒãƒå‡¦ç†ã§æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—
                    batch_size = 50  # Meta APIã®ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ€å¤§æ•°
                    for batch_start in range(0, len(campaign_level_campaigns), batch_size):
                        batch_end = min(batch_start + batch_size, len(campaign_level_campaigns))
                        batch_campaigns = campaign_level_campaigns[batch_start:batch_end]
                        batch_num = (batch_start // batch_size) + 1
                        total_batches = (len(campaign_level_campaigns) + batch_size - 1) // batch_size
                        
                        print(f"[Meta API] Processing {period_name} unique reach batch {batch_num}/{total_batches} ({len(batch_campaigns)} campaigns)")
                        
                        batch_requests = []
                        for campaign in batch_campaigns:
                            campaign_id = campaign.get('id')
                            campaign_name = campaign.get('name', 'Unknown')
                            # æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—ï¼ˆtime_incrementãªã—ã§æœŸé–“å…¨ä½“ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼‰
                            period_reach_fields = "campaign_id,campaign_name,reach"
                            # time_incrementã‚’æŒ‡å®šã—ãªã„ã“ã¨ã§ã€æœŸé–“å…¨ä½“ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿ï¼ˆ1ä»¶ï¼‰ã‚’å–å¾—
                            relative_url = f"{campaign_id}/insights?fields={period_reach_fields}&time_range={period_time_range_encoded}&level=campaign&limit=100"
                            
                            # ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å ´åˆã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆURLã‚’ãƒ­ã‚°å‡ºåŠ›
                            if 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°' in campaign_name and period_name == 'all':
                                print(f"[Meta API] ğŸ” DEBUG: Request URL for '{campaign_name}' ({period_name}):")
                                print(f"[Meta API]   Campaign ID: {campaign_id}")
                                print(f"[Meta API]   Time Range Encoded: {period_time_range_encoded}")
                                print(f"[Meta API]   Relative URL: {relative_url}")
                            
                            batch_requests.append({
                                "method": "GET",
                                "relative_url": relative_url
                            })
                        
                        try:
                            batch_response = await client.post(batch_url, params={
                                "access_token": access_token,
                                "batch": json.dumps(batch_requests, separators=(',', ':'))
                            })
                            batch_response.raise_for_status()
                            batch_data = batch_response.json()
                            
                            for idx, batch_item in enumerate(batch_data):
                                campaign = batch_campaigns[idx]
                                campaign_name = campaign.get('name', 'Unknown')
                                
                                if batch_item.get('code') == 200:
                                    try:
                                        item_body = json.loads(batch_item.get('body', '{}'))
                                        period_insights = item_body.get('data', [])
                                        if period_insights:
                                            # time_incrementãªã—ã®å ´åˆã€æœŸé–“å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã¯1ä»¶ã®ã¿
                                            insight_data = period_insights[0]
                                            
                                            # reachãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ—¢ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’è¡¨ã—ã¦ã„ã‚‹ï¼ˆtime_incrementãªã—ã®å ´åˆï¼‰
                                            period_reach = safe_int(insight_data.get('reach', 0), 0)
                                            period_map[campaign_name] = period_reach
                                            print(f"[Meta API] {period_name} unique reach for '{campaign_name}': {period_reach:,}")
                                            
                                            # ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å ´åˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
                                            if 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°' in campaign_name and period_name == 'all':
                                                print(f"[Meta API] ğŸ” DEBUG: Full response data for '{campaign_name}' ({period_name}):")
                                                print(f"[Meta API]   Raw insight_data: {json.dumps(insight_data, indent=2, ensure_ascii=False)}")
                                                print(f"[Meta API]   Reach value (raw): {insight_data.get('reach')}")
                                                print(f"[Meta API]   Reach value (parsed): {period_reach:,}")
                                                print(f"[Meta API]   Campaign ID: {insight_data.get('campaign_id')}")
                                                print(f"[Meta API]   Campaign Name: {insight_data.get('campaign_name')}")
                                                print(f"[Meta API]   All keys in insight_data: {list(insight_data.keys())}")
                                        else:
                                            print(f"[Meta API] âš ï¸ No {period_name} reach data for '{campaign_name}' (empty data array)")
                                            # ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å ´åˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’ãƒ­ã‚°å‡ºåŠ›
                                            if 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°' in campaign_name and period_name == 'all':
                                                print(f"[Meta API] ğŸ” DEBUG: Empty response for '{campaign_name}' ({period_name}):")
                                                print(f"[Meta API]   Response body: {json.dumps(item_body, indent=2, ensure_ascii=False)}")
                                    except json.JSONDecodeError as e:
                                        print(f"[Meta API] Error parsing {period_name} reach response for {campaign_name}: {str(e)}")
                                        print(f"[Meta API] Response body: {batch_item.get('body', '{}')}")
                                else:
                                    error_body = batch_item.get('body', '{}')
                                    try:
                                        error_data = json.loads(error_body) if isinstance(error_body, str) else error_body
                                        error_msg = error_data.get('error', {}).get('message', str(error_body))
                                        print(f"[Meta API] Error fetching {period_name} reach for {campaign_name}: {error_msg}")
                                    except:
                                        print(f"[Meta API] Error fetching {period_name} reach for {campaign_name}: {error_body}")
                        except Exception as e:
                            print(f"[Meta API] Error processing {period_name} unique reach batch {batch_num}: {str(e)}")
                            import traceback
                            traceback.print_exc()
                            continue
                    
                    print(f"[Meta API] {period_name} unique reach map created: {len(period_map)} campaigns")
                
                # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å…¨æœŸé–“ã®å€¤ã‚’period_unique_reachã«ã‚‚è¨­å®š
                campaign_period_reach_map = campaign_period_reach_all_map.copy()
                print(f"[Meta API] Period unique reach map created: {len(campaign_period_reach_map)} campaigns")
                print(f"[Meta API] Sample period unique reach values: {dict(list(campaign_period_reach_map.items())[:5])}")
            else:
                print(f"[Meta API] No campaigns found, skipping period unique reach fetch")
                campaign_period_reach_map = {}
            
            # Insightsãƒ‡ãƒ¼ã‚¿ã‚’Campaignãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³/åºƒå‘Šã‚»ãƒƒãƒˆ/åºƒå‘Šãƒ¬ãƒ™ãƒ«ï¼‰
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ã¯è¡Œã‚ãªã„ï¼ˆæ–°è¦ãƒ‡ãƒ¼ã‚¿ã®ã¿è¿½åŠ ã™ã‚‹æ–¹å¼ã«å¤‰æ›´ï¼‰
            # éå»ã®æ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã¯ç¢ºå®šå¾Œã¯å¤‰æ›´ã•ã‚Œãªã„ãŸã‚ã€æ›´æ–°å‡¦ç†ã¯ä¸è¦
            # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿½åŠ ã™ã‚‹å®Ÿè£…
            print(f"[Meta API] Starting data sync for account {account_id} (adding new data only, not deleting existing data)")
            
            saved_count = 0
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚»ãƒƒãƒˆï¼ˆcampaign_name, date, meta_account_idã®çµ„ã¿åˆã‚ã›ï¼‰
            seen_records = set()
            
            # ãƒ‡ãƒãƒƒã‚°: å–å¾—ã—ãŸInsightsãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª
            if all_insights:
                all_dates = [insight.get('date_start') for insight in all_insights if insight.get('date_start')]
                unique_dates = sorted(list(set(all_dates)))
                print(f"[Meta API] ===== Insights Data Analysis ======")
                print(f"[Meta API] Total insights retrieved: {len(all_insights)}")
                print(f"[Meta API] Total unique dates: {len(unique_dates)}")
                if len(unique_dates) > 0:
                    print(f"[Meta API] Date range: {unique_dates[0]} to {unique_dates[-1]}")
                    print(f"[Meta API] First 10 unique dates: {unique_dates[:10]}")
                    print(f"[Meta API] Last 10 unique dates: {unique_dates[-10:]}")
                    # å„æ—¥ä»˜ã®ä»¶æ•°ã‚’ç¢ºèª
                    date_counts = {}
                    for date in all_dates:
                        date_counts[date] = date_counts.get(date, 0) + 1
                    print(f"[Meta API] Date distribution (first 10 dates):")
                    for date in unique_dates[:10]:
                        print(f"  {date}: {date_counts.get(date, 0)} insights")
                if len(unique_dates) == 1:
                    print(f"[Meta API] âš ï¸ WARNING: All insights have the same date! This indicates time_increment may not be working.")
                    print(f"[Meta API] Requested date range: {start_date_str} to {end_date_str}")
                    print(f"[Meta API] Actual date received: {unique_dates[0]}")
                print(f"[Meta API] =====================================")
            
            for insight in all_insights:
                try:
                    # æ—¥ä»˜ã‚’å–å¾—
                    date_str = insight.get('date_start')
                    if not date_str:
                        print(f"[Meta API] WARNING: Skipping insight with no date_start: {insight}")
                        continue
                    campaign_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³/åºƒå‘Šã‚»ãƒƒãƒˆ/åºƒå‘Šãƒ¬ãƒ™ãƒ«ï¼‰
                    campaign_name = insight.get('campaign_name', 'Unknown')
                    # ad_set_name ã¨ ad_name ã‚’ Meta API ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å–å¾—
                    ad_set_name = insight.get('adset_name')  # åºƒå‘Šã‚»ãƒƒãƒˆåï¼ˆã‚ã‚Œã°ï¼‰
                    ad_name = insight.get('ad_name')          # åºƒå‘Šåï¼ˆã‚ã‚Œã°ï¼‰
                    
                    # æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰
                    # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå‰ã¯ã€period_unique_reachã®ã¿ã‚’ä½¿ç”¨
                    period_unique_reach = 0
                    period_unique_reach_7days = 0
                    period_unique_reach_30days = 0
                    period_unique_reach_all = 0
                    
                    if (not ad_set_name or ad_set_name == '') and (not ad_name or ad_name == ''):
                        # æœŸé–“åˆ¥ã®ãƒãƒƒãƒ—ã‹ã‚‰å–å¾—ï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¾Œã«æœ‰åŠ¹åŒ–ï¼‰
                        try:
                            period_unique_reach_7days = campaign_period_reach_7days_map.get(campaign_name, 0)
                            period_unique_reach_30days = campaign_period_reach_30days_map.get(campaign_name, 0)
                            period_unique_reach_all = campaign_period_reach_all_map.get(campaign_name, 0)
                        except:
                            # ãƒãƒƒãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€å…¨æœŸé–“ã®ãƒãƒƒãƒ—ã‹ã‚‰å–å¾—
                            period_unique_reach_all = campaign_period_reach_map.get(campaign_name, 0)
                        
                        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å…¨æœŸé–“ã®å€¤ã‚’period_unique_reachã«ã‚‚è¨­å®š
                        if period_unique_reach_all > 0:
                            period_unique_reach = period_unique_reach_all
                        else:
                            period_unique_reach = campaign_period_reach_map.get(campaign_name, 0)
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
                    if saved_count < 3:
                        print(f"[Meta API] Processing insight: campaign={campaign_name}, date={campaign_date}")
                        print(f"  Raw data: spend={insight.get('spend')}, impressions={insight.get('impressions')}, clicks={insight.get('clicks')}, inline_link_clicks={insight.get('inline_link_clicks')}")
                    
                    spend = safe_float(insight.get('spend'), 0.0)
                    impressions = safe_int(insight.get('impressions'), 0)
                    all_clicks = safe_int(insight.get('clicks'), 0)
                    inline_link_clicks = safe_int(insight.get('inline_link_clicks'), 0)
                    reach = safe_int(insight.get('reach'), 0)
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
                    if saved_count < 3:
                        print(f"  Parsed: spend={spend}, impressions={impressions}, clicks={all_clicks}, inline_link_clicks={inline_link_clicks}, reach={reach}")
                    
                    # ã‚¯ãƒªãƒƒã‚¯æ•°ã¯inline_link_clicksã‚’ä½¿ç”¨
                    clicks = inline_link_clicks if inline_link_clicks > 0 else all_clicks
                    link_clicks = inline_link_clicks if inline_link_clicks > 0 else all_clicks
                    
                    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé–¢é€£ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    engagements = safe_int(insight.get('engagements'), 0)
                    if engagements == 0:
                        actions = insight.get('actions', [])
                        if actions:
                            for action in actions:
                                if action.get('action_type') == 'post_engagement':
                                    engagements += safe_int(action.get('value'), 0)
                    
                    # landing_page_viewsã¯actionsã‹ã‚‰æŠ½å‡º
                    landing_page_views = 0
                    actions = insight.get('actions', [])
                    if actions:
                        for action in actions:
                            if action.get('action_type') == 'landing_page_view':
                                landing_page_views += safe_int(action.get('value'), 0)
                    
                    frequency = safe_float(insight.get('frequency'), 0.0)
                    if frequency == 0 and reach > 0:
                        frequency = (impressions / reach) if reach > 0 else 0.0
                    
                    # conversionsã¨conversion_valueã‚’å–å¾—
                    # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã”ã¨ã«ä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆã™ã¹ã¦ã‚’åˆè¨ˆã—ãªã„ï¼‰
                    # ã„ãšã‚Œã‹1ã¤ã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’ä½¿ç”¨
                    conversions_data = insight.get('conversions', [])
                    conversions = 0
                    conversion_value = 0.0
                    selected_conversion_type = "none"
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
                    if saved_count < 3:
                        print(f"[Meta API] Conversions data for {campaign_name}: {conversions_data}")
                    
                    if conversions_data:
                        # å„ªå…ˆé †ä½ã«åŸºã¥ã„ã¦ã€æœ€åˆã«è¦‹ã¤ã‹ã£ãŸä¸»è¦ãªã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                        # å„ªå…ˆé †ä½: è³¼å…¥é–¢é€£ > ç™»éŒ²é–¢é€£ > ãƒªãƒ¼ãƒ‰é–¢é€£ > ãã®ä»–
                        found_conversion = False
                        
                        # 1. è³¼å…¥é–¢é€£ã‚’å„ªå…ˆï¼ˆpurchase, omni_purchase, offsite_conversion.fb_pixel_purchase, onsite_conversion.meta_purchaseï¼‰
                        for conv in conversions_data:
                            if isinstance(conv, dict):
                                action_type = conv.get('action_type', '')
                                if (action_type in ['purchase', 'omni_purchase'] or
                                    action_type == 'offsite_conversion.fb_pixel_purchase' or
                                    action_type == 'onsite_conversion.meta_purchase' or
                                    action_type.startswith('offsite_conversion.fb_pixel_purchase') or
                                    action_type.startswith('onsite_conversion.meta_purchase')):
                                    value = conv.get('value', 0)
                                    try:
                                        conversions = int(value) if isinstance(value, (int, str)) else 0
                                        selected_conversion_type = action_type
                                        found_conversion = True
                                        if saved_count < 3:
                                            print(f"[Meta API] Selected conversion type (purchase): {action_type} = {conversions}")
                                        break
                                    except (ValueError, TypeError):
                                        pass
                        
                        # 2. è³¼å…¥é–¢é€£ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ç™»éŒ²é–¢é€£ã‚’ãƒã‚§ãƒƒã‚¯
                        if not found_conversion:
                            for conv in conversions_data:
                                if isinstance(conv, dict):
                                    action_type = conv.get('action_type', '')
                                    if (action_type == 'complete_registration' or
                                        action_type == 'offsite_conversion.fb_pixel_complete_registration' or
                                        action_type.startswith('offsite_conversion.fb_pixel_complete_registration')):
                                        value = conv.get('value', 0)
                                        try:
                                            conversions = int(value) if isinstance(value, (int, str)) else 0
                                            selected_conversion_type = action_type
                                            found_conversion = True
                                            if saved_count < 3:
                                                print(f"[Meta API] Selected conversion type (registration): {action_type} = {conversions}")
                                            break
                                        except (ValueError, TypeError):
                                            pass
                        
                        # 3. ç™»éŒ²é–¢é€£ã‚‚è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ãƒªãƒ¼ãƒ‰é–¢é€£ã‚’ãƒã‚§ãƒƒã‚¯
                        if not found_conversion:
                            for conv in conversions_data:
                                if isinstance(conv, dict):
                                    action_type = conv.get('action_type', '')
                                    if (action_type == 'lead' or
                                        action_type == 'offsite_conversion.fb_pixel_lead' or
                                        action_type.startswith('offsite_conversion.fb_pixel_lead')):
                                        value = conv.get('value', 0)
                                        try:
                                            conversions = int(value) if isinstance(value, (int, str)) else 0
                                            selected_conversion_type = action_type
                                            found_conversion = True
                                            if saved_count < 3:
                                                print(f"[Meta API] Selected conversion type (lead): {action_type} = {conversions}")
                                            break
                                        except (ValueError, TypeError):
                                            pass
                        
                        # 4. ä¸Šè¨˜ã®ã„ãšã‚Œã‚‚è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€æœ€åˆã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨
                        if not found_conversion and conversions_data:
                            conv = conversions_data[0]
                            if isinstance(conv, dict):
                                action_type = conv.get('action_type', '')
                                value = conv.get('value', 0)
                                try:
                                    conversions = int(value) if isinstance(value, (int, str)) else 0
                                    selected_conversion_type = action_type
                                    if saved_count < 3:
                                        print(f"[Meta API] Selected conversion type (first available): {action_type} = {conversions}")
                                except (ValueError, TypeError):
                                    conversions = 0
                            else:
                                try:
                                    conversions = int(conv) if isinstance(conv, (int, str)) else 0
                                    selected_conversion_type = "unknown"
                                    if saved_count < 3:
                                        print(f"[Meta API] Selected conversion type (unknown format): {conversions}")
                                except (ValueError, TypeError):
                                    conversions = 0
                    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: actionsã‹ã‚‰å–å¾—ï¼ˆconversionsãŒ0ã®å ´åˆã®ã¿ï¼‰
                    if conversions == 0:
                        actions = insight.get('actions', [])
                        # åŒã˜å„ªå…ˆé †ä½ã§æ¤œç´¢
                        for action in actions:
                            if isinstance(action, dict):
                                action_type = action.get('action_type', '')
                                if (action_type in ['purchase', 'omni_purchase'] or
                                    action_type == 'offsite_conversion.fb_pixel_purchase' or
                                    action_type == 'onsite_conversion.meta_purchase'):
                                    value = action.get('value', 0)
                                    try:
                                        conversions = int(value) if isinstance(value, (int, str)) else 0
                                        selected_conversion_type = action_type
                                        break
                                    except (ValueError, TypeError):
                                        pass
                                elif (action_type == 'complete_registration' or
                                      action_type == 'offsite_conversion.fb_pixel_complete_registration'):
                                    value = action.get('value', 0)
                                    try:
                                        conversions = int(value) if isinstance(value, (int, str)) else 0
                                        selected_conversion_type = action_type
                                        break
                                    except (ValueError, TypeError):
                                        pass
                                elif (action_type == 'lead' or
                                      action_type == 'offsite_conversion.fb_pixel_lead'):
                                    value = action.get('value', 0)
                                    try:
                                        conversions = int(value) if isinstance(value, (int, str)) else 0
                                        selected_conversion_type = action_type
                                        break
                                    except (ValueError, TypeError):
                                        pass
                    
                    # conversion_valueã‚’å–å¾—ï¼ˆaction_valuesã‹ã‚‰ï¼‰
                    # è³¼å…¥é–¢é€£ã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’å–å¾—ï¼ˆåˆè¨ˆã—ãªã„ï¼‰
                    action_values = insight.get('action_values', [])
                    conversion_value = 0.0
                    
                    if action_values:
                        # è³¼å…¥é–¢é€£ã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¾¡å€¤ã®ã¿ã‚’å–å¾—ï¼ˆæœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ï¼‰
                        for av in action_values:
                            if isinstance(av, dict):
                                av_type = av.get('action_type', '')
                                if (av_type in ['purchase', 'omni_purchase'] or
                                    av_type == 'offsite_conversion.fb_pixel_purchase' or
                                    av_type == 'onsite_conversion.meta_purchase' or
                                    av_type.startswith('offsite_conversion.fb_pixel_purchase') or
                                    av_type.startswith('onsite_conversion.meta_purchase')):
                                    value = av.get('value', 0)
                                    try:
                                        conversion_value = float(value) if isinstance(value, (int, float, str)) else 0.0
                                        break
                                    except (ValueError, TypeError):
                                        pass
                    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: actionsã‹ã‚‰å–å¾—ï¼ˆconversion_valueãŒ0ã®å ´åˆã®ã¿ï¼‰
                    if conversion_value == 0:
                        actions = insight.get('actions', [])
                        for action in actions:
                            action_type = action.get('action_type', '')
                            if (action_type in ['purchase', 'omni_purchase'] or
                                action_type == 'offsite_conversion.fb_pixel_purchase' or
                                action_type == 'onsite_conversion.meta_purchase'):
                                value = action.get('value', 0)
                                try:
                                    conversion_value = float(value) if isinstance(value, (int, float, str)) else 0.0
                                    break
                                except (ValueError, TypeError):
                                    pass
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
                    ctr = (clicks / impressions * 100) if impressions > 0 else 0
                    cpc = (spend / clicks) if clicks > 0 else 0
                    cpm = (spend / impressions * 1000) if impressions > 0 else 0
                    cpa = (spend / conversions) if conversions > 0 else 0
                    cvr = (conversions / clicks * 100) if clicks > 0 else 0
                    roas = (conversion_value / spend) if spend > 0 else 0
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
                    if saved_count < 3:
                        print(f"  Final values: spend={spend}, impressions={impressions}, clicks={clicks}, conversions={conversions}, reach={reach}")
                        print(f"  Selected conversion type: {selected_conversion_type}")
                        if clicks > 0:
                            cvr = (conversions / clicks * 100)
                            print(f"  Conversion check: conversions={conversions}, clicks={clicks}, CVR={cvr:.2f}%")
                        else:
                            print(f"  Conversion check: conversions={conversions}, clicks={clicks} (no clicks)")
                    
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜campaign_name, ad_set_name, ad_name, date, meta_account_idã®çµ„ã¿åˆã‚ã›ã¯1ä»¶ã®ã¿ï¼‰
                    record_key = (campaign_name, ad_set_name, ad_name, campaign_date, account_id)
                    if record_key in seen_records:
                        print(f"[Meta API] WARNING: Duplicate record skipped: {campaign_name} / {ad_set_name} / {ad_name} on {campaign_date}")
                        continue
                    seen_records.add(record_key)
                    
                    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªï¼ˆåŒã˜campaign_name, ad_set_name, ad_name, date, meta_account_idã®çµ„ã¿åˆã‚ã›ï¼‰
                    existing_campaign = db.query(Campaign).filter(
                        Campaign.user_id == user.id,
                        Campaign.meta_account_id == account_id,
                        Campaign.campaign_name == campaign_name,
                        Campaign.ad_set_name == ad_set_name,
                        Campaign.ad_name == ad_name,
                        Campaign.date == campaign_date
                    ).first()
                    
                    # æœŸé–“åˆ¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ•°ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
                    # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå‰ã¯ã€period_unique_reachã®ã¿ã‚’ä½¿ç”¨
                    period_unique_reach = 0
                    period_unique_reach_7days = 0
                    period_unique_reach_30days = 0
                    period_unique_reach_all = 0
                    
                    if not ad_set_name and not ad_name:  # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿
                        # æœŸé–“åˆ¥ã®ãƒãƒƒãƒ—ã‹ã‚‰å–å¾—ï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¾Œã«æœ‰åŠ¹åŒ–ï¼‰
                        try:
                            period_unique_reach_7days = campaign_period_reach_7days_map.get(campaign_name, 0)
                            period_unique_reach_30days = campaign_period_reach_30days_map.get(campaign_name, 0)
                            period_unique_reach_all = campaign_period_reach_all_map.get(campaign_name, 0)
                        except:
                            # ãƒãƒƒãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€å…¨æœŸé–“ã®ãƒãƒƒãƒ—ã‹ã‚‰å–å¾—
                            period_unique_reach_all = campaign_period_reach_map.get(campaign_name, 0)
                        
                        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å…¨æœŸé–“ã®å€¤ã‚’period_unique_reachã«ã‚‚è¨­å®š
                        if period_unique_reach_all > 0:
                            period_unique_reach = period_unique_reach_all
                        else:
                            period_unique_reach = campaign_period_reach_map.get(campaign_name, 0)
                        
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœŸé–“åˆ¥ã®å€¤ãŒ0ã®å ´åˆã€æ—¥æ¬¡ã®reachã‚’ä½¿ç”¨ï¼ˆãŸã ã—ã€ã“ã‚Œã¯æœ¬æ¥ã®å‹•ä½œã§ã¯ãªã„ï¼‰
                        if period_unique_reach == 0 and reach > 0:
                            period_unique_reach = reach
                            print(f"[Meta API] Using daily reach as period_unique_reach (fallback) for '{campaign_name}': {period_unique_reach:,}")
                    
                    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
                    if existing_campaign:
                        # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã§ã€æœŸé–“åˆ¥ã®period_unique_reachã‚’æ›´æ–°ï¼ˆ0ã§ã‚‚æ›´æ–°ï¼‰
                        if not ad_set_name and not ad_name:
                            # æœŸé–“åˆ¥ã®å€¤ã‚’æ›´æ–°
                            existing_campaign.period_unique_reach = period_unique_reach  # å¾Œæ–¹äº’æ›æ€§
                            
                            # æ–°ã—ã„ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿æ›´æ–°ï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¾Œã«æœ‰åŠ¹åŒ–ï¼‰
                            try:
                                existing_campaign.period_unique_reach_7days = period_unique_reach_7days
                                existing_campaign.period_unique_reach_30days = period_unique_reach_30days
                                existing_campaign.period_unique_reach_all = period_unique_reach_all
                            except AttributeError:
                                # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç„¡è¦–ï¼ˆå¿µã®ãŸã‚ï¼‰
                                pass
                            
                            db.commit()
                            print(f"[Meta API] Updated period_unique_reach for existing record: {campaign_name} on {campaign_date} -> 7days:{period_unique_reach_7days:,}, 30days:{period_unique_reach_30days:,}, all:{period_unique_reach_all:,}")
                        else:
                            print(f"[Meta API] Skipping existing record: {campaign_name} / {ad_set_name} / {ad_name} on {campaign_date}")
                        continue
                    
                    # æ–°è¦ä½œæˆï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ï¼‰
                    campaign = Campaign(
                        user_id=user.id,
                        upload_id=upload.id,
                        meta_account_id=account_id,
                        date=campaign_date,
                        campaign_name=campaign_name,
                        ad_set_name=ad_set_name,  # åºƒå‘Šã‚»ãƒƒãƒˆåï¼ˆã‚ã‚Œã°ï¼‰
                        ad_name=ad_name,  # åºƒå‘Šåï¼ˆã‚ã‚Œã°ï¼‰
                        cost=Decimal(str(spend)),
                        impressions=impressions,
                        clicks=clicks,
                        conversions=conversions,
                        conversion_value=Decimal(str(conversion_value)),
                        reach=reach,
                        period_unique_reach=period_unique_reach,  # å¾Œæ–¹äº’æ›æ€§ï¼ˆå…¨æœŸé–“ã®å€¤ï¼‰
                        engagements=engagements,
                        link_clicks=link_clicks,
                        landing_page_views=landing_page_views,
                        ctr=Decimal(str(round(ctr, 2))),
                        cpc=Decimal(str(round(cpc, 2))),
                        cpm=Decimal(str(round(cpm, 2))),
                        cpa=Decimal(str(round(cpa, 2))),
                        cvr=Decimal(str(round(cvr, 2))),
                        roas=Decimal(str(round(roas, 2)))
                    )
                    
                    # æ–°ã—ã„ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¨­å®šï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¾Œã«æœ‰åŠ¹åŒ–ï¼‰
                    # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå¾Œã¯ã€ã“ã‚Œã‚‰ã®ã‚«ãƒ©ãƒ ã‚‚è¨­å®šã•ã‚Œã‚‹
                    try:
                        campaign.period_unique_reach_7days = period_unique_reach_7days
                        campaign.period_unique_reach_30days = period_unique_reach_30days
                        campaign.period_unique_reach_all = period_unique_reach_all
                    except AttributeError:
                        # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç„¡è¦–ï¼ˆå¿µã®ãŸã‚ï¼‰
                        pass
                    
                    db.add(campaign)
                    saved_count += 1
                    
                    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆæœ€åˆã®æ•°ä»¶ã®ã¿ï¼‰
                    if saved_count <= 3:
                        print(f"  âœ“ Saved campaign record #{saved_count}: {campaign_name} on {campaign_date}")
                except Exception as e:
                    print(f"[Meta API] Error processing insight: {str(e)}")
                    continue
            
            # Uploadãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°
            upload.row_count = saved_count
            if all_insights:
                dates = [datetime.strptime(i.get('date_start', ''), '%Y-%m-%d').date() for i in all_insights if i.get('date_start')]
                if dates:
                    upload.start_date = min(dates)
                    upload.end_date = max(dates)
            
            db.commit()
            print(f"[Meta API] Saved {saved_count} campaign-level records")
    except Exception as e:
        db.rollback()
        raise

@router.get("/accounts/")
async def get_meta_accounts(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé€£æºã—ã¦ã„ã‚‹Metaåºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼ˆã‚¢ã‚»ãƒƒãƒˆï¼‰ä¸€è¦§ã‚’å–å¾—"""
    try:
        print(f"[Meta Accounts] Getting accounts for user: {current_user.id}")
        
        # Meta APIã‹ã‚‰å…¨ã¦ã®åºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ï¼ˆã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚‹å ´åˆï¼‰
        account_names = {}
        all_account_ids_from_api = []
        if current_user.meta_access_token:
            try:
                print(f"[Meta Accounts] Fetching account names from Meta API...")
                async with httpx.AsyncClient() as client:
                    # ã™ã¹ã¦ã®åºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
                    accounts_url = "https://graph.facebook.com/v24.0/me/adaccounts"
                    accounts_params = {
                        "access_token": current_user.meta_access_token,
                        "fields": "account_id,id,name",
                        "limit": 100  # Meta APIã®æœ€å¤§å–å¾—ä»¶æ•°
                    }
                    
                    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ï¼ˆã™ã¹ã¦ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ï¼‰
                    accounts_page_count = 0
                    while True:
                        accounts_page_count += 1
                        print(f"[Meta Accounts] Fetching accounts page {accounts_page_count}...")
                        accounts_response = await client.get(accounts_url, params=accounts_params)
                        accounts_response.raise_for_status()
                        accounts_data = accounts_response.json()
                        
                        if "data" in accounts_data:
                            for account in accounts_data["data"]:
                                # Meta APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã¯ã€idã¨account_idã®ä¸¡æ–¹ãŒå­˜åœ¨ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
                                # idãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ act_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼ˆä¾‹: act_343589077304936ï¼‰
                                # account_idãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ act_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒå«ã¾ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼ˆä¾‹: 343589077304936ï¼‰
                                account_id_from_id = account.get("id")  # act_343589077304936 ã®å½¢å¼
                                account_id_from_account_id = account.get("account_id")  # 343589077304936 ã®å½¢å¼
                                
                                # account_idã‚’æ±ºå®šï¼ˆact_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ãŸå½¢å¼ã‚’ä½¿ç”¨ï¼‰
                                if account_id_from_account_id:
                                    account_id = account_id_from_account_id
                                elif account_id_from_id:
                                    # idãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰ act_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤
                                    account_id = account_id_from_id.replace("act_", "") if account_id_from_id.startswith("act_") else account_id_from_id
                                else:
                                    continue
                                
                                account_name = account.get("name")
                                if not account_name or account_name.strip() == "":
                                    account_name = account_id
                                print(f"[Meta Accounts] Account ID: {account_id}, Name: {account_name}")
                                # account_idã¨idã®ä¸¡æ–¹ã®ã‚­ãƒ¼ã§ä¿å­˜ï¼ˆã©ã¡ã‚‰ã§ã‚‚æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«ï¼‰
                                account_names[account_id] = account_name
                                if account_id_from_id and account_id_from_id != account_id:
                                    account_names[account_id_from_id] = account_name
                                    # act_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—ã®å½¢å¼ã‚‚ä¿å­˜
                                    account_id_without_act = account_id_from_id.replace("act_", "") if account_id_from_id.startswith("act_") else account_id_from_id
                                    if account_id_without_act != account_id:
                                        account_names[account_id_without_act] = account_name
                                all_account_ids_from_api.append(account_id)
                        
                        print(f"[Meta Accounts] Retrieved {len(accounts_data.get('data', []))} accounts (total: {len(all_account_ids_from_api)})")
                        
                        # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        paging = accounts_data.get('paging', {})
                        next_url = paging.get('next')
                        
                        if not next_url:
                            # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã¯çµ‚äº†
                            print(f"[Meta Accounts] No more account pages. Total accounts retrieved: {len(all_account_ids_from_api)}")
                            break
                        
                        # æ¬¡ã®ãƒšãƒ¼ã‚¸ã®URLã‚’è¨­å®šï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ï¼‰
                        accounts_url = next_url
                        accounts_params = {}
                    
                    print(f"[Meta Accounts] Fetched {len(account_names)} account names from Meta API")
                    print(f"[Meta Accounts] Account names dict: {account_names}")
                    print(f"[Meta Accounts] All account IDs from API: {all_account_ids_from_api}")
            except Exception as e:
                import traceback
                print(f"[Meta Accounts] Error fetching account names: {str(e)}")
                print(f"[Meta Accounts] Error details: {traceback.format_exc()}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’ä½¿ç”¨
        
        # Meta APIã‹ã‚‰å–å¾—ã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’ä½¿ç”¨ï¼ˆãªã‘ã‚Œã°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ï¼‰
        if all_account_ids_from_api:
            account_ids = all_account_ids_from_api
            print(f"[Meta Accounts] Using {len(account_ids)} account IDs from Meta API")
        else:
            # Meta APIã‹ã‚‰å–å¾—ã§ããªã‹ã£ãŸå ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
            accounts = db.query(Campaign.meta_account_id).filter(
                Campaign.user_id == current_user.id,
                Campaign.meta_account_id.isnot(None)
            ).distinct().all()
            account_ids = [acc[0] for acc in accounts if acc[0]]
            print(f"[Meta Accounts] Using {len(account_ids)} account IDs from database (fallback)")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®å ´åˆã§ã‚‚ã€Meta APIã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’å–å¾—ã‚’è©¦ã¿ã‚‹
            if account_ids and current_user.meta_access_token:
                # account_namesã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®ã¿å–å¾—
                missing_names = [aid for aid in account_ids if aid not in account_names]
                if missing_names:
                    try:
                        print(f"[Meta Accounts] Attempting to fetch account names for {len(missing_names)} accounts from database")
                        async with httpx.AsyncClient() as client:
                            for account_id in missing_names:
                                try:
                                    # å€‹åˆ¥ã«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—
                                    account_url = f"https://graph.facebook.com/v24.0/{account_id}"
                                    account_params = {
                                        "access_token": current_user.meta_access_token,
                                        "fields": "account_id,id,name"
                                    }
                                    account_response = await client.get(account_url, params=account_params)
                                    account_response.raise_for_status()
                                    account_data = account_response.json()
                                    
                                    # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
                                    if "error" in account_data:
                                        print(f"[Meta Accounts] Error from Meta API for {account_id}: {account_data.get('error')}")
                                        account_names[account_id] = account_id
                                        continue
                                    
                                    account_name = account_data.get("name")
                                    if account_name and account_name.strip():
                                        account_names[account_id] = account_name
                                        print(f"[Meta Accounts] Fetched name for {account_id}: {account_name}")
                                    else:
                                        account_names[account_id] = account_id
                                        print(f"[Meta Accounts] Name is empty for {account_id}, using account_id")
                                except Exception as e:
                                    print(f"[Meta Accounts] Error fetching name for {account_id}: {str(e)}")
                                    account_names[account_id] = account_id
                    except Exception as e:
                        print(f"[Meta Accounts] Error fetching account names from Meta API: {str(e)}")
                        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€account_idã‚’ãã®ã¾ã¾ä½¿ç”¨
                        for account_id in missing_names:
                            if account_id not in account_names:
                                account_names[account_id] = account_id
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å®Ÿéš›ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹meta_account_idã®å½¢å¼ã‚’ç¢ºèª
        existing_account_ids = db.query(Campaign.meta_account_id).filter(
            Campaign.user_id == current_user.id,
            Campaign.meta_account_id.isnot(None)
        ).distinct().all()
        existing_account_ids_list = [acc[0] for acc in existing_account_ids if acc[0]]
        print(f"[Meta Accounts] Existing meta_account_ids in DB: {existing_account_ids_list}")
        
        # å„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        result = []
        for account_id in account_ids:
            try:
                # account_idã®å½¢å¼ã‚’ç¢ºèªï¼ˆact_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹ã‹ã©ã†ã‹ï¼‰
                # Meta APIã‹ã‚‰å–å¾—ã—ãŸaccount_idã¯ act_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—ã®å½¢å¼ï¼ˆä¾‹: 343589077304936ï¼‰
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¯ act_343589077304936 ã®å½¢å¼ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å½¢å¼ï¼ˆact_ä»˜ãï¼‰ã§æ¤œç´¢ã™ã‚‹
                account_id_with_prefix = f"act_{account_id}" if not account_id.startswith("act_") else account_id
                account_id_without_prefix = account_id.replace("act_", "") if account_id.startswith("act_") else account_id
                
                print(f"[Meta Accounts] Searching for account_id: {account_id} (with prefix: {account_id_with_prefix}, without prefix: {account_id_without_prefix})")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹å½¢å¼ã‚’ç¢ºèª
                matching_ids = [aid for aid in existing_account_ids_list if account_id_with_prefix == aid or account_id_without_prefix == aid.replace("act_", "")]
                print(f"[Meta Accounts] Matching account_ids in DB: {matching_ids}")
                
                # å„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—ï¼ˆå…¨ãƒ¬ãƒ™ãƒ«åˆè¨ˆï¼‰
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¯ act_ ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã‚Œã§æ¤œç´¢
                total_count = db.query(Campaign).filter(
                    Campaign.user_id == current_user.id,
                    Campaign.meta_account_id == account_id_with_prefix
                ).count()
                
                print(f"[Meta Accounts] Query result for {account_id} (searching with {account_id_with_prefix}): total_count={total_count}")
                
                # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ•°ã‚’å–å¾—
                unique_campaigns = db.query(Campaign.campaign_name).filter(
                    Campaign.user_id == current_user.id,
                    Campaign.meta_account_id == account_id_with_prefix,
                    or_(
                        Campaign.ad_set_name == '',
                        Campaign.ad_set_name.is_(None)
                    ),
                    or_(
                        Campaign.ad_name == '',
                        Campaign.ad_name.is_(None)
                    )
                ).distinct().count()
                
                # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿æ—¥ä»˜ã‚’å–å¾—
                latest_date = db.query(func.max(Campaign.date)).filter(
                    Campaign.user_id == current_user.id,
                    Campaign.meta_account_id == account_id_with_prefix
                ).scalar()
                
                # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã‚’å–å¾—ï¼ˆMeta APIã‹ã‚‰å–å¾—ã§ããŸå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼‰
                account_name = account_names.get(account_id)
                if not account_name or account_name.strip() == "":
                    # account_namesã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€Meta APIã‹ã‚‰å€‹åˆ¥ã«å–å¾—ã‚’è©¦ã¿ã‚‹
                    if current_user.meta_access_token:
                        try:
                            async with httpx.AsyncClient() as client:
                                account_url = f"https://graph.facebook.com/v24.0/{account_id}"
                                account_params = {
                                    "access_token": current_user.meta_access_token,
                                    "fields": "account_id,id,name"
                                }
                                account_response = await client.get(account_url, params=account_params)
                                account_response.raise_for_status()
                                account_data = account_response.json()
                                
                                if "error" not in account_data and "name" in account_data:
                                    account_name = account_data.get("name")
                                    if account_name and account_name.strip():
                                        account_names[account_id] = account_name
                                        print(f"[Meta Accounts] Fetched name for {account_id}: {account_name}")
                                    else:
                                        account_name = account_id
                                else:
                                    account_name = account_id
                        except Exception as e:
                            print(f"[Meta Accounts] Error fetching name for {account_id}: {str(e)}")
                            account_name = account_id
                    else:
                        account_name = account_id
                
                print(f"[Meta Accounts] For account_id {account_id}, final name: {account_name}")
                print(f"[Meta Accounts] Account {account_id} stats: data_count={total_count}, campaign_count={unique_campaigns}")
                
                # nameãŒç©ºã®å ´åˆã¯account_idã‚’ä½¿ç”¨
                final_name = account_name if account_name and account_name.strip() else account_id
                
                account_result = {
                    "account_id": account_id,
                    "name": final_name,
                    "data_count": total_count,
                    "campaign_count": unique_campaigns,
                    "latest_date": str(latest_date) if latest_date else None
                }
                print(f"[Meta Accounts] Account result: {account_result}")
                result.append(account_result)
            except Exception as e:
                import traceback
                print(f"[Meta Accounts] Error processing account {account_id}: {str(e)}")
                print(f"[Meta Accounts] Error details: {traceback.format_exc()}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                continue
        
        print(f"[Meta Accounts] Returning {len(result)} accounts")
        return {
            "accounts": result,
            "total": len(result)
        }
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta Accounts] Unexpected error: {str(e)}")
        print(f"[Meta Accounts] Error type: {type(e).__name__}")
        print(f"[Meta Accounts] Error details: {error_details}")
        raise HTTPException(
            status_code=500,
            detail=f"ã‚¢ã‚»ãƒƒãƒˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
        )

@router.delete("/delete-all")
async def delete_all_meta_data(
    account_id: Optional[str] = Query(None, description="å‰Šé™¤ã™ã‚‹Metaåºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ + CSVãƒ‡ãƒ¼ã‚¿ï¼‰"),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    æœ¬ç•ªç’°å¢ƒãƒ†ã‚¹ãƒˆç”¨: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨æœŸé–“Metaãƒ‡ãƒ¼ã‚¿ã¨CSVãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    """
    try:
        print(f"[Meta Delete All] Starting deletion for user: {current_user.id}")
        
        total_deleted = 0
        
        if account_id:
            # æŒ‡å®šã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®Meta APIãƒ‡ãƒ¼ã‚¿ã®ã¿å‰Šé™¤ï¼ˆå…¨ãƒ¬ãƒ™ãƒ«ï¼‰
            delete_query = db.query(Campaign).filter(
                Campaign.user_id == current_user.id,
                Campaign.meta_account_id == account_id
            )
            print(f"[Meta Delete All] Filtering by account_id: {account_id} (Meta API data only)")
            count_before = delete_query.count()
            print(f"[Meta Delete All] Records to delete: {count_before}")
            
            if count_before > 0:
                deleted_count = delete_query.delete(synchronize_session=False)
                total_deleted += deleted_count
                print(f"[Meta Delete All] Deleted {deleted_count} Meta API records for account {account_id}")
        else:
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆMeta APIãƒ‡ãƒ¼ã‚¿ + CSVãƒ‡ãƒ¼ã‚¿ã€å…¨ãƒ¬ãƒ™ãƒ«ï¼‰
            # ã¾ãšã€å‰Šé™¤å‰ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—
            count_before = db.query(Campaign).filter(
                Campaign.user_id == current_user.id
            ).count()
            print(f"[Meta Delete All] Total records to delete: {count_before}")
            
            if count_before == 0:
                return {
                    "status": "success",
                    "message": "å‰Šé™¤ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                    "deleted_count": 0
                }
            
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆMeta APIãƒ‡ãƒ¼ã‚¿ + CSVãƒ‡ãƒ¼ã‚¿ã€å…¨ãƒ¬ãƒ™ãƒ«ï¼‰
            delete_query = db.query(Campaign).filter(
                Campaign.user_id == current_user.id
            )
            deleted_count = delete_query.delete(synchronize_session=False)
            total_deleted = deleted_count
            print(f"[Meta Delete All] Deleted {deleted_count} total records (Meta API + CSV, all levels)")
        
        # ã‚³ãƒŸãƒƒãƒˆã—ã¦å‰Šé™¤ã‚’ç¢ºå®š
        db.commit()
        print(f"[Meta Delete All] Successfully committed deletion: {total_deleted} records")
        
        # å‰Šé™¤å¾Œã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèª
        count_after = db.query(Campaign).filter(
            Campaign.user_id == current_user.id
        ).count()
        print(f"[Meta Delete All] Records remaining after deletion: {count_after}")
        
        return {
            "status": "success",
            "message": f"{total_deleted}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼ˆMeta APIãƒ‡ãƒ¼ã‚¿ + CSVãƒ‡ãƒ¼ã‚¿ã€å…¨ãƒ¬ãƒ™ãƒ«ï¼‰",
            "deleted_count": total_deleted,
            "remaining_count": count_after
        }
    except Exception as e:
        db.rollback()
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta Delete All] Error: {str(e)}")
        print(f"[Meta Delete All] Error details: {error_details}")
        raise HTTPException(
            status_code=500,
            detail=f"ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )

@router.post("/sync-all")
async def sync_all_meta_data(
    account_id: Optional[str] = Query(None, description="åŒæœŸã™ã‚‹Metaåºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆï¼‰"),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    æœ¬ç•ªç’°å¢ƒãƒ†ã‚¹ãƒˆç”¨: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨æœŸé–“Metaãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—
    """
    try:
        print(f"[Meta Sync All] Starting full period sync for user: {current_user.id}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ç¢ºèª
        if not current_user.meta_access_token:
            raise HTTPException(
                status_code=400,
                detail="Metaã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
        
        # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®ãƒªã‚¹ãƒˆã‚’å–å¾—
        if account_id:
            # æŒ‡å®šã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®ã¿
            account_ids = [account_id]
            print(f"[Meta Sync All] Syncing specific account: {account_id}")
        else:
            # å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—
            try:
                async with httpx.AsyncClient() as client:
                    accounts_url = "https://graph.facebook.com/v24.0/me/adaccounts"
                    accounts_params = {
                        "access_token": current_user.meta_access_token,
                        "fields": "id,name",
                        "limit": 100
                    }
                    
                    accounts_response = await client.get(accounts_url, params=accounts_params)
                    accounts_response.raise_for_status()
                    accounts_data = accounts_response.json()
                    
                    account_ids = [acc.get("id") for acc in accounts_data.get("data", [])]
                    print(f"[Meta Sync All] Found {len(account_ids)} accounts to sync")
            except Exception as e:
                import traceback
                print(f"[Meta Sync All] Error fetching accounts: {str(e)}")
                print(f"[Meta Sync All] Error details: {traceback.format_exc()}")
                raise HTTPException(
                    status_code=500,
                    detail=f"ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
                )
        
        if not account_ids:
            raise HTTPException(
                status_code=400,
                detail="åŒæœŸã™ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
            )
        
        # å„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        # ã¾ãšã€å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆsync_meta_data_to_campaignså†…ã®å‰Šé™¤å‡¦ç†ã¯æœŸé–“å†…ã®ã¿ã®ãŸã‚ï¼‰
        # CSVãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆé‡è¤‡ã‚’é˜²ããŸã‚ï¼‰
        print(f"[Meta Sync All] Deleting all existing data (including CSV data) for {len(account_ids)} account(s) before sync...")
        
        # 1. Meta APIãƒ‡ãƒ¼ã‚¿ï¼ˆmeta_account_idãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ï¼‰ã‚’å‰Šé™¤
        for acc_id in account_ids:
            try:
                # ã“ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆæœŸé–“åˆ¶é™ãªã—ï¼‰
                delete_count = db.query(Campaign).filter(
                    Campaign.user_id == current_user.id,
                    Campaign.meta_account_id == acc_id,
                    Campaign.ad_set_name.is_(None),
                    Campaign.ad_name.is_(None)
                ).delete(synchronize_session=False)
                print(f"[Meta Sync All] Deleted {delete_count} Meta API records for account {acc_id}")
            except Exception as e:
                import traceback
                print(f"[Meta Sync All] Error deleting Meta API data for account {acc_id}: {str(e)}")
                print(f"[Meta Sync All] Error details: {traceback.format_exc()}")
        
        # 2. CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆmeta_account_idãŒNULLï¼‰ã‚‚å‰Šé™¤ï¼ˆé‡è¤‡ã‚’é˜²ããŸã‚ï¼‰
        try:
            csv_delete_count = db.query(Campaign).filter(
                Campaign.user_id == current_user.id,
                or_(
                    Campaign.meta_account_id.is_(None),
                    Campaign.meta_account_id == ''
                ),
                Campaign.ad_set_name.is_(None),
                Campaign.ad_name.is_(None)
            ).delete(synchronize_session=False)
            print(f"[Meta Sync All] Deleted {csv_delete_count} CSV upload records")
        except Exception as e:
            import traceback
            print(f"[Meta Sync All] Error deleting CSV data: {str(e)}")
            print(f"[Meta Sync All] Error details: {traceback.format_exc()}")
        
        # ã‚³ãƒŸãƒƒãƒˆã—ã¦å‰Šé™¤ã‚’ç¢ºå®š
        db.commit()
        print(f"[Meta Sync All] Deletion completed (Meta API + CSV data), starting data sync...")
        
        total_synced = 0
        results = []
        
        for idx, acc_id in enumerate(account_ids):
            try:
                print(f"[Meta Sync All] Syncing account {idx + 1}/{len(account_ids)}: {acc_id}")
                await sync_meta_data_to_campaigns(
                    current_user,
                    current_user.meta_access_token,
                    acc_id,
                    db,
                    days=None  # å…¨æœŸé–“ï¼ˆ37ãƒ¶æœˆï¼‰
                )
                total_synced += 1
                results.append({
                    "account_id": acc_id,
                    "status": "success"
                })
                print(f"[Meta Sync All] Successfully synced account: {acc_id}")
            except Exception as e:
                import traceback
                error_details = traceback.format_exc()
                print(f"[Meta Sync All] Error syncing account {acc_id}: {str(e)}")
                print(f"[Meta Sync All] Error details: {error_details}")
                results.append({
                    "account_id": acc_id,
                    "status": "error",
                    "error": str(e)
                })
                # 1ã¤ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€ä»–ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®åŒæœŸã¯ç¶šè¡Œ
                continue
        
        return {
            "status": "success",
            "message": f"{total_synced}/{len(account_ids)}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã—ã¾ã—ãŸ",
            "total_accounts": len(account_ids),
            "synced_accounts": total_synced,
            "results": results
        }
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta Sync All] Unexpected error: {str(e)}")
        print(f"[Meta Sync All] Error details: {error_details}")
        raise HTTPException(
            status_code=500,
            detail=f"ãƒ‡ãƒ¼ã‚¿åŒæœŸã‚¨ãƒ©ãƒ¼: {str(e)}"
        )

@router.get("/insights")
async def get_meta_insights(
    since: Optional[str] = None,
    until: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®Insightsã‚’å–å¾—ï¼ˆåºƒå‘Šã‚»ãƒƒãƒˆãƒ»åºƒå‘Šãƒ¬ãƒ™ãƒ«ã¯å–å¾—ã—ãªã„ï¼‰"""
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ç¢ºèª
    if not current_user.meta_account_id or not current_user.meta_access_token:
        raise HTTPException(
            status_code=400,
            detail="Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šç”»é¢ã§Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚"
        )
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ—¥ä»˜ç¯„å›²ï¼ˆæœ€è¿‘37ãƒ¶æœˆé–“ã€æœªæ¥ã®æ—¥ä»˜ã‚’é¿ã‘ã‚‹ï¼‰
    # JSTï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰ã§æ˜¨æ—¥ã‚’è¨ˆç®—
    from datetime import timezone
    jst = timezone(timedelta(hours=9))  # JST = UTC+9
    today_jst = datetime.now(jst).date()
    yesterday = today_jst - timedelta(days=1)
    
    if not since:
        until_dt = yesterday
        since_dt = until_dt - timedelta(days=1095)  # 37ãƒ¶æœˆ
        since = since_dt.strftime('%Y-%m-%d')
    if not until:
        until = yesterday.strftime('%Y-%m-%d')
    
    # Meta APIã®æœŸé–“åˆ¶é™ã‚’ç¢ºèª
    campaign_fields = "campaign_id,campaign_name,date_start,spend,impressions,clicks,inline_link_clicks,reach,actions,conversions,action_values,frequency"
    has_reach = "reach" in campaign_fields.lower()
    has_breakdowns = False  # ç¾åœ¨ã®å®Ÿè£…ã§ã¯breakdownsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„
    
    if has_reach and has_breakdowns:
        max_days = 394  # 13ãƒ¶æœˆ
        print(f"[Meta API] /insights endpoint: Reach with breakdowns detected - limiting to 13 months")
    else:
        max_days = 1095  # 37ãƒ¶æœˆ
        print(f"[Meta API] /insights endpoint: Standard limit - 37 months")
    
    # æœŸé–“ã‚’åˆ¶é™ï¼ˆ37ãƒ¶æœˆã¾ãŸã¯13ãƒ¶æœˆï¼‰
    try:
        until_dt = datetime.strptime(until, '%Y-%m-%d')
        since_dt = datetime.strptime(since, '%Y-%m-%d')
        
        if (until_dt - since_dt).days > max_days:
            since_dt = until_dt - timedelta(days=max_days)
            since = since_dt.strftime('%Y-%m-%d')
            print(f"[Meta API] Date range limited to {max_days} days: {since} to {until}")
    except Exception as e:
        print(f"[Meta API] Error parsing dates: {e}")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€è¿‘37ãƒ¶æœˆé–“ï¼ˆJSTåŸºæº–ï¼‰
        until_dt = yesterday
        since_dt = until_dt - timedelta(days=1095)  # 37ãƒ¶æœˆ
        since = since_dt.strftime('%Y-%m-%d')
        until = until_dt.strftime('%Y-%m-%d')
    
    # Meta Graph APIã‚’å‘¼ã³å‡ºã—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰
    account_id = current_user.meta_account_id
    access_token = current_user.meta_access_token
    
    try:
        async with httpx.AsyncClient() as client:
            all_insights = []
            
            # ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ä¸€è¦§ã‚’å–å¾—
            campaigns_url = f"https://graph.facebook.com/v24.0/{account_id}/campaigns"
            campaigns_params = {
                "access_token": access_token,
                "fields": "id,name",
                "limit": 100
            }
            
            all_campaigns = []
            while True:
                campaigns_response = await client.get(campaigns_url, params=campaigns_params)
                campaigns_response.raise_for_status()
                campaigns_data = campaigns_response.json()
                page_campaigns = campaigns_data.get('data', [])
                all_campaigns.extend(page_campaigns)
                
                paging = campaigns_data.get('paging', {})
                next_url = paging.get('next')
                if not next_url:
                    break
                campaigns_url = next_url
                campaigns_params = {}
            
            # å„ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®Insightsã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã¿ï¼‰
            time_range_dict = {"since": since, "until": until}
            time_range_json = json.dumps(time_range_dict, separators=(',', ':'))
            
            for campaign in all_campaigns:
                campaign_id = campaign['id']
                insights_url = f"https://graph.facebook.com/v24.0/{campaign_id}/insights"
                insights_params = {
                    "access_token": access_token,
                    "fields": campaign_fields,
                    "time_range": time_range_json,
                    "level": "campaign",
                    "limit": 100
                }
                
                try:
                    insights_response = await client.get(insights_url, params=insights_params)
                    insights_response.raise_for_status()
                    insights_data = insights_response.json()
                    page_insights = insights_data.get('data', [])
                    all_insights.extend(page_insights)
                    
                    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†
                    paging = insights_data.get('paging', {})
                    while 'next' in paging:
                        next_url = paging['next']
                        next_response = await client.get(next_url)
                        next_response.raise_for_status()
                        next_data = next_response.json()
                        next_insights = next_data.get('data', [])
                        all_insights.extend(next_insights)
                        paging = next_data.get('paging', {})
                except Exception as e:
                    print(f"[Meta API] Error fetching insights for campaign {campaign_id}: {str(e)}")
                    continue
            
            return {
                "insights": all_insights,
                "total": len(all_insights),
                "period": {
                "since": since,
                    "until": until
                }
            }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Insightså–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )

@router.get("/oauth/authorize")
async def meta_oauth_authorize(
    request: Request,
    current_user: User = Depends(get_current_user)
):
    """Meta OAuthèªè¨¼ã‚’é–‹å§‹ - èªè¨¼URLã‚’ç”Ÿæˆã—ã¦ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ"""
    if not settings.META_APP_ID:
        raise HTTPException(
            status_code=500,
            detail="Meta OAuthãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"
        )

@router.get("/oauth/authorize")
async def meta_oauth_authorize(
    request: Request,
    current_user: User = Depends(get_current_user)
):
    """Meta OAuthèªè¨¼ã‚’é–‹å§‹ - èªè¨¼URLã‚’ç”Ÿæˆã—ã¦ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ"""
    if not settings.META_APP_ID:
        raise HTTPException(
            status_code=500,
            detail="Meta OAuthãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"
        )
    
    # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURIã‚’è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å›ºå®šï¼‰
    redirect_uri = settings.META_REDIRECT_URI or "https://mieru-ai-production.up.railway.app/api/meta/oauth/callback"
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰å–å¾—ï¼ˆX-Frontend-URLï¼‰ã¾ãŸã¯Origin/Refererã‹ã‚‰åˆ¤å®š
    frontend_url_from_header = request.headers.get("X-Frontend-URL")
    origin = request.headers.get("origin") or request.headers.get("referer", "")
    
    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤å®š
    is_local = (
        frontend_url_from_header and (
            "localhost" in frontend_url_from_header or 
            "127.0.0.1" in frontend_url_from_header
        )
    ) or (
        "localhost" in origin or 
        "127.0.0.1" in origin or
        "localhost:3000" in origin or
        "localhost:5173" in origin or
        origin.startswith("http://localhost") or
        origin.startswith("http://127.0.0.1")
    )
    
    if is_local:
        frontend_url_for_state = "http://localhost:3000"
    else:
        frontend_url_for_state = settings.FRONTEND_URL or "https://mieru.netlify.app"
    
    print(f"[Meta OAuth] Frontend URL from header (X-Frontend-URL): {frontend_url_from_header}")
    print(f"[Meta OAuth] Origin: {origin}")
    print(f"[Meta OAuth] Detected frontend URL for state: {frontend_url_for_state}")
    
    # ã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆCSRFå¯¾ç­–ï¼‰
    state = secrets.token_urlsafe(32)
    # ã‚¹ãƒ†ãƒ¼ãƒˆã«ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã‚’å«ã‚ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {state}:{user_id}:{frontend_url}
    state_with_user = f"{state}:{current_user.id}:{urllib.parse.quote(frontend_url_for_state)}"
    
    # ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€¤ã‚’ãƒ­ã‚°å‡ºåŠ›
    print(f"[Meta OAuth] OAuth URL Parameters (authorize endpoint):")
    print(f"  - client_id: {settings.META_APP_ID}")
    print(f"  - redirect_uri (raw): {redirect_uri}")
    print(f"  - redirect_uri (encoded): {urllib.parse.quote(redirect_uri)}")
    print(f"  - scope: ads_read,ads_management,business_management")
    print(f"  - response_type: code")
    print(f"  - state (raw): {state_with_user}")
    print(f"  - state (encoded): {urllib.parse.quote(state_with_user)}")
    
    # Meta OAuthèªè¨¼URLã‚’ç”Ÿæˆ
    oauth_url = (
        f"https://www.facebook.com/v24.0/dialog/oauth?"
        f"client_id={settings.META_APP_ID}&"
        f"redirect_uri={urllib.parse.quote(redirect_uri)}&"
        f"scope=ads_read,ads_management,business_management&"
        f"state={urllib.parse.quote(state_with_user)}&"
        f"response_type=code"
    )
    
    # ãƒ‡ãƒãƒƒã‚°: ç”Ÿæˆã•ã‚ŒãŸURLå…¨ä½“ã‚’ãƒ­ã‚°å‡ºåŠ›
    print(f"[Meta OAuth] Generated OAuth URL (authorize endpoint): {oauth_url}")
    
    return RedirectResponse(url=oauth_url)

@router.get("/oauth/authorize-url/")
async def meta_oauth_authorize_url(
    request: Request,
    current_user: User = Depends(get_current_user)
):
    """Meta OAuthèªè¨¼URLã‚’å–å¾—ï¼ˆJSONå½¢å¼ã§è¿”ã™ï¼‰"""
    try:
        if not settings.META_APP_ID:
            raise HTTPException(
                status_code=500,
                detail="Meta OAuthãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ç’°å¢ƒå¤‰æ•°ã«META_APP_IDã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            )
        
        # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURIã‚’è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å›ºå®šï¼‰
        redirect_uri = settings.META_REDIRECT_URI or "https://mieru-ai-production.up.railway.app/api/meta/oauth/callback"
        
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰å–å¾—ï¼ˆX-Frontend-URLï¼‰ã¾ãŸã¯Origin/Refererã‹ã‚‰åˆ¤å®š
        frontend_url_from_header = request.headers.get("X-Frontend-URL")
        origin = request.headers.get("origin") or request.headers.get("referer", "")
        
        # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤å®š
        is_local = (
            frontend_url_from_header and (
                "localhost" in frontend_url_from_header or 
                "127.0.0.1" in frontend_url_from_header
            )
        ) or (
            "localhost" in origin or 
            "127.0.0.1" in origin or
            "localhost:3000" in origin or
            "localhost:5173" in origin or
            origin.startswith("http://localhost") or
            origin.startswith("http://127.0.0.1")
        )
        
        if is_local:
            frontend_url_for_state = "http://localhost:3000"
        else:
            frontend_url_for_state = settings.FRONTEND_URL or "https://mieru.netlify.app"
        
        print(f"[Meta OAuth] Frontend URL from header (X-Frontend-URL): {frontend_url_from_header}")
        print(f"[Meta OAuth] Origin: {origin}")
        print(f"[Meta OAuth] Detected frontend URL for state: {frontend_url_for_state}")
        
        # ã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆCSRFå¯¾ç­–ï¼‰
        state = secrets.token_urlsafe(32)
        # ã‚¹ãƒ†ãƒ¼ãƒˆã«ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã‚’å«ã‚ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {state}:{user_id}:{frontend_url}
        state_with_user = f"{state}:{current_user.id}:{urllib.parse.quote(frontend_url_for_state)}"
        
        # ãƒ‡ãƒãƒƒã‚°: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€¤ã‚’ãƒ­ã‚°å‡ºåŠ›
        print(f"[Meta OAuth] OAuth URL Parameters:")
        print(f"  - client_id: {settings.META_APP_ID}")
        print(f"  - redirect_uri (raw): {redirect_uri}")
        print(f"  - redirect_uri (encoded): {urllib.parse.quote(redirect_uri)}")
        print(f"  - scope: ads_read,ads_management,business_management")
        print(f"  - response_type: code")
        print(f"  - state (raw): {state_with_user}")
        print(f"  - state (encoded): {urllib.parse.quote(state_with_user)}")
        
        # Meta OAuthèªè¨¼URLã‚’ç”Ÿæˆ
        oauth_url = (
            f"https://www.facebook.com/v24.0/dialog/oauth?"
            f"client_id={settings.META_APP_ID}&"
            f"redirect_uri={urllib.parse.quote(redirect_uri)}&"
            f"scope=ads_read,ads_management,business_management&"
            f"state={urllib.parse.quote(state_with_user)}&"
            f"response_type=code"
        )
        
        # ãƒ‡ãƒãƒƒã‚°: ç”Ÿæˆã•ã‚ŒãŸURLå…¨ä½“ã‚’ãƒ­ã‚°å‡ºåŠ›
        print(f"[Meta OAuth] Generated OAuth URL: {oauth_url}")
        
        return {"oauth_url": oauth_url}
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta OAuth] Error in authorize-url: {str(e)}")
        print(f"[Meta OAuth] Error details: {error_details}")
        raise HTTPException(
            status_code=500,
            detail=f"OAuthèªè¨¼URLã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
        )

@router.get("/oauth/callback/")
async def meta_oauth_callback(
    request: Request,
    code: Optional[str] = Query(None, description="OAuthèªè¨¼ã‚³ãƒ¼ãƒ‰"),
    state: Optional[str] = Query(None, description="ã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆCSRFå¯¾ç­–ï¼‰"),
    error: Optional[str] = Query(None, description="ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"),
    error_reason: Optional[str] = Query(None, description="ã‚¨ãƒ©ãƒ¼ç†ç”±"),
    error_description: Optional[str] = Query(None, description="ã‚¨ãƒ©ãƒ¼è©³ç´°"),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: Session = Depends(get_db)
):
    """Meta OAuthã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ - ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¦ä¿å­˜"""
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã¯å¾Œã§stateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã™ã‚‹ï¼ˆåˆæœŸå€¤ã¨ã—ã¦è¨­å®šï¼‰
    frontend_url = settings.FRONTEND_URL or "https://mieru.netlify.app"
    
    # localhostã®å ´åˆã€https://ã‚’http://ã«å¼·åˆ¶çš„ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def normalize_localhost_url(url: str) -> str:
        """localhostã®URLã‚’å¸¸ã«http://ã«å¤‰æ›ï¼ˆhttps://ã¯è¨±å¯ã—ãªã„ï¼‰"""
        if not url:
            return url
        # localhostã¾ãŸã¯127.0.0.1ã®å ´åˆã€https://ã‚’http://ã«å¼·åˆ¶å¤‰æ›
        # ã‚ˆã‚Šå …ç‰¢ãªå¤‰æ›: æ­£è¦è¡¨ç¾ã§ã¯ãªãã€æ–‡å­—åˆ—ã®é–‹å§‹éƒ¨åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
        original_url = url
        if url.startswith('https://localhost') or url.startswith('https://127.0.0.1'):
            normalized = url.replace('https://', 'http://', 1)  # æœ€åˆã®1å›ã®ã¿ç½®æ›
            print(f"[Meta OAuth] Normalized URL: {original_url} -> {normalized}")
            return normalized
        elif 'localhost' in url or '127.0.0.1' in url:
            # å¿µã®ãŸã‚ã€URLå†…ã®ã©ã“ã‹ã«https://localhostã‚„https://127.0.0.1ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã‚‚å¤‰æ›
            normalized = url.replace('https://localhost', 'http://localhost')
            normalized = normalized.replace('https://127.0.0.1', 'http://127.0.0.1')
            if normalized != url:
                print(f"[Meta OAuth] Normalized URL (fallback): {original_url} -> {normalized}")
            return normalized
        return url
    
    # ã‚¨ãƒ©ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼ˆèªè¨¼æ‹’å¦ãªã©ï¼‰
    if error:
        error_message = error_description or error_reason or error
        error_url = f"{normalize_localhost_url(frontend_url)}/settings?meta_oauth=error&message={urllib.parse.quote(error_message)}"
        # æœ€çµ‚ç¢ºèª: error_urlãŒhttps://localhostã‚’å«ã‚“ã§ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    
    # codeã¨stateãŒå¿…é ˆ
    if not code:
        error_url = f"{normalize_localhost_url(frontend_url)}/settings?meta_oauth=error&message={urllib.parse.quote('èªè¨¼ã‚³ãƒ¼ãƒ‰ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    
    if not state:
        error_url = f"{normalize_localhost_url(frontend_url)}/settings?meta_oauth=error&message={urllib.parse.quote('ã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    
    if not settings.META_APP_ID or not settings.META_APP_SECRET:
        error_url = f"{normalize_localhost_url(frontend_url)}/settings?meta_oauth=error&message={urllib.parse.quote('Meta OAuthãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    
    # ãƒ‡ãƒãƒƒã‚°: ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã«å—ã‘å–ã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
    print(f"[Meta OAuth] Callback received parameters:")
    print(f"  - code: {code[:20] + '...' if code and len(code) > 20 else code}")
    print(f"  - state (raw): {state}")
    print(f"  - state (length): {len(state) if state else 0}")
    
    # ã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’URLãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆMetaãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è¿”ã™å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
    try:
        decoded_state = urllib.parse.unquote(state)
        print(f"  - state (decoded): {decoded_state}")
        state = decoded_state
    except Exception as e:
        print(f"  - state decode error: {str(e)}")
        # ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®stateã‚’ä½¿ç”¨
    
    # ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã‚’å–å¾—
    try:
        print(f"[Meta OAuth] Parsing state: {state}")
        
        # stateãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {state}:{user_id}:{frontend_url}
        # frontend_urlã¯URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æœ€åˆã®2ã¤ã®ã‚³ãƒ­ãƒ³ã§åˆ†å‰²
        # ä¾‹: "abc123:user-id:http%3A//localhost%3A3000" -> ["abc123", "user-id", "http%3A//localhost%3A3000"]
        colon_count = state.count(':')
        print(f"  - state colon count: {colon_count}")
        
        if colon_count < 2:
            print(f"[Meta OAuth] ERROR: State has less than 2 colons: {colon_count}")
            normalized_url = normalize_localhost_url(frontend_url)
            error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote('ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™')}"
            if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
                error_url = error_url.replace('https://localhost', 'http://localhost')
                error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
            return RedirectResponse(url=error_url, status_code=302)
        
        # æœ€åˆã®2ã¤ã®ã‚³ãƒ­ãƒ³ã®ä½ç½®ã‚’æ¢ã™
        first_colon = state.find(':')
        second_colon = state.find(':', first_colon + 1)
        
        if first_colon == -1 or second_colon == -1:
            print(f"[Meta OAuth] ERROR: Could not find 2 colons in state")
            normalized_url = normalize_localhost_url(frontend_url)
            error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote('ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™')}"
            if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
                error_url = error_url.replace('https://localhost', 'http://localhost')
                error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
            return RedirectResponse(url=error_url, status_code=302)
        
        # 3ã¤ã®éƒ¨åˆ†ã«åˆ†å‰²
        state_token = state[:first_colon]
        user_id_str = state[first_colon + 1:second_colon]
        frontend_url_encoded = state[second_colon + 1:]
        
        print(f"  - state_token: {state_token[:20]}...")
        print(f"  - user_id_str: {user_id_str}")
        print(f"  - frontend_url_encoded: {frontend_url_encoded}")
        
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰URLã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        frontend_url_from_state = urllib.parse.unquote(frontend_url_encoded)
        print(f"  - frontend_url from state (decoded): {frontend_url_from_state}")
        
        # localhostã®å ´åˆã€https://ã‚’http://ã«å¼·åˆ¶çš„ã«å¤‰æ›ï¼ˆnormalize_localhost_urlé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
        frontend_url = normalize_localhost_url(frontend_url_from_state)
        if frontend_url != frontend_url_from_state:
            print(f"[Meta OAuth] Converted HTTPS to HTTP for localhost: {frontend_url_from_state} -> {frontend_url}")
        else:
            print(f"[Meta OAuth] Using frontend URL from state: {frontend_url}")
        
        # user_idã¯UUIDå½¢å¼ãªã®ã§ã€UUIDã¨ã—ã¦æ‰±ã†
        try:
            user_id = uuid.UUID(user_id_str)
        except ValueError as uuid_error:
            print(f"  - UUID conversion error: {str(uuid_error)}")
            raise ValueError(f"Invalid UUID format: {user_id_str}")
        print(f"  - user_id (UUID): {user_id}")
    except ValueError as e:
        print(f"[Meta OAuth] ERROR: ValueError when parsing state: {str(e)}")
        print(f"  - state_parts: {state_parts if 'state_parts' in locals() else 'N/A'}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    except IndexError as e:
        print(f"[Meta OAuth] ERROR: IndexError when parsing state: {str(e)}")
        print(f"  - state_parts: {state_parts if 'state_parts' in locals() else 'N/A'}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    except Exception as e:
        print(f"[Meta OAuth] ERROR: Unexpected error when parsing state: {str(e)}")
        import traceback
        print(f"  - traceback: {traceback.format_exc()}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURIï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å›ºå®šï¼‰
    redirect_uri = settings.META_REDIRECT_URI or "https://mieru-ai-production.up.railway.app/api/meta/oauth/callback"
    
    try:
        # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
        async with httpx.AsyncClient() as client:
            token_url = "https://graph.facebook.com/v24.0/oauth/access_token"
            token_params = {
                "client_id": settings.META_APP_ID,
                "client_secret": settings.META_APP_SECRET,
                "redirect_uri": redirect_uri,
                "code": code
            }
            
            token_response = await client.get(token_url, params=token_params)
            token_response.raise_for_status()
            token_data = token_response.json()
            
            if "error" in token_data:
                raise HTTPException(
                    status_code=400,
                    detail=f"ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {token_data.get('error', {}).get('message', 'Unknown error')}"
                )
            
            access_token = token_data.get("access_token")
            if not access_token:
                raise HTTPException(status_code=400, detail="ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            # é•·æœŸãƒˆãƒ¼ã‚¯ãƒ³ã«å¤‰æ›ï¼ˆ60æ—¥æœ‰åŠ¹ï¼‰
            exchange_url = "https://graph.facebook.com/v24.0/oauth/access_token"
            exchange_params = {
                "grant_type": "fb_exchange_token",
                "client_id": settings.META_APP_ID,
                "client_secret": settings.META_APP_SECRET,
                "fb_exchange_token": access_token
            }
            
            exchange_response = await client.get(exchange_url, params=exchange_params)
            exchange_response.raise_for_status()
            exchange_data = exchange_response.json()
            
            long_lived_token = exchange_data.get("access_token", access_token)
            
            # åºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
            accounts_url = "https://graph.facebook.com/v24.0/me/adaccounts"
            accounts_params = {
                "access_token": long_lived_token,
                "fields": "account_id,id,name",
                "limit": 100  # Meta APIã®æœ€å¤§å–å¾—ä»¶æ•°
            }
            
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ï¼ˆã™ã¹ã¦ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ï¼‰
            accounts = []
            accounts_page_count = 0
            while True:
                accounts_page_count += 1
                print(f"[Meta OAuth] Fetching accounts page {accounts_page_count}...")
                accounts_response = await client.get(accounts_url, params=accounts_params)
                accounts_response.raise_for_status()
                accounts_data = accounts_response.json()
                
                if "error" in accounts_data:
                    raise HTTPException(
                        status_code=400,
                        detail=f"åºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {accounts_data.get('error', {}).get('message', 'Unknown error')}"
                    )
                
                # å–å¾—ã—ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¿½åŠ 
                page_accounts = accounts_data.get("data", [])
                accounts.extend(page_accounts)
                print(f"[Meta OAuth] Retrieved {len(page_accounts)} accounts (total: {len(accounts)})")
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                paging = accounts_data.get('paging', {})
                next_url = paging.get('next')
                
                if not next_url:
                    # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã¯çµ‚äº†
                    print(f"[Meta OAuth] No more account pages. Total accounts retrieved: {len(accounts)}")
                    break
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ã®URLã‚’è¨­å®šï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ï¼‰
                accounts_url = next_url
                accounts_params = {}  # URLã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã‚¯ãƒªã‚¢
            
            if not accounts:
                raise HTTPException(
                    status_code=400,
                    detail="åºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚Metaåºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                )
            
            # å–å¾—ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
            print(f"[Meta OAuth] ===== ACCOUNTS RETRIEVED =====")
            for idx, account in enumerate(accounts):
                account_id_tmp = account.get("id")
                account_name_tmp = account.get("name", "Unknown")
                print(f"[Meta OAuth] Account {idx + 1}: {account_name_tmp} ({account_id_tmp})")
            print(f"[Meta OAuth] =============================")
            
            # ã™ã¹ã¦ã®åºƒå‘Šã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ä¿å­˜
            # æœ€åˆã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’ä¿å­˜ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
            first_account = accounts[0]
            account_id = first_account.get("id")  # act_123456789å½¢å¼
            account_name_first = first_account.get("name", "Unknown")
            
            print(f"[Meta OAuth] Selected first account: {account_name_first} ({account_id})")
            print(f"[Meta OAuth] This account ID will be saved to user.meta_account_id")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®šã‚’æ›´æ–°ï¼ˆæœ€åˆã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’ä¿å­˜ï¼‰
            user.meta_account_id = account_id
            user.meta_access_token = long_lived_token
            db.commit()
            db.refresh(user)
            
            print(f"[Meta OAuth] User meta_account_id updated to: {user.meta_account_id}")
            
            # å…¨æœŸé–“ï¼ˆ37ãƒ¶æœˆï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å–å¾—
            print(f"[Meta OAuth] Starting data sync for user {user.id}")
            print(f"[Meta OAuth] Found {len(accounts)} ad account(s)")
            print(f"[Meta OAuth] Starting background sync for full period (37 months)...")
            
            # ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã«æ¸¡ã™ãŸã‚ã«ã‚³ãƒ”ãƒ¼
            accounts_for_background = [{"id": acc.get("id"), "name": acc.get("name", "Unknown")} for acc in accounts]
            user_id_for_background = user.id
            access_token_for_background = long_lived_token  # ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚ä¿å­˜
            
            def sync_full_period_background_sync():
                """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆåŒæœŸé–¢æ•°ãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰"""
                import asyncio
                from ..database import SessionLocal
                
                print(f"[Meta OAuth] Background sync: Task started")
                print(f"[Meta OAuth] Background sync: Accounts to sync: {len(accounts_for_background)}")
                
                # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç”¨ï¼‰
                try:
                    loop = asyncio.get_event_loop()
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                
                async def sync_all_accounts_async():
                    """éåŒæœŸã§å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
                    background_db = SessionLocal()
                    try:
                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å†å–å¾—
                        background_user = background_db.query(User).filter(User.id == user_id_for_background).first()
                        if not background_user:
                            print(f"[Meta OAuth] Background sync: ERROR - User not found (user_id: {user_id_for_background})")
                            return
                        
                        print(f"[Meta OAuth] Background sync: User found: {background_user.id}")
                        print(f"[Meta OAuth] Background sync: User meta_account_id: {background_user.meta_account_id}")
                        print(f"[Meta OAuth] Background sync: Starting full period sync for user {background_user.id}")
                        
                        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ï¼ˆä¿å­˜ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ï¼‰
                        access_token = access_token_for_background
                        if not access_token:
                            print(f"[Meta OAuth] Background sync: ERROR - No access token found")
                            return
                        
                        for idx, account in enumerate(accounts_for_background):
                            account_id_to_sync = account.get("id")
                            account_name = account.get("name", "Unknown")
                            print(f"[Meta OAuth] Background sync: Syncing account {idx + 1}/{len(accounts_for_background)} (full period): {account_name} ({account_id_to_sync})")
                            try:
                                await sync_meta_data_to_campaigns(background_user, access_token, account_id_to_sync, background_db, days=None)
                                print(f"[Meta OAuth] Background sync: Successfully synced full period for {account_name}")
                            except Exception as account_error:
                                import traceback
                                print(f"[Meta OAuth] Background sync: ERROR syncing full period for {account_name}: {str(account_error)}")
                                print(f"[Meta OAuth] Background sync: Error details: {traceback.format_exc()}")
                                continue
                        
                        print(f"[Meta OAuth] Background sync: Full period sync completed for user {background_user.id}")
                    except Exception as sync_error:
                        import traceback
                        print(f"[Meta OAuth] Background sync: CRITICAL ERROR: {str(sync_error)}")
                        print(f"[Meta OAuth] Background sync: Error details: {traceback.format_exc()}")
                    finally:
                        background_db.close()
                        print(f"[Meta OAuth] Background sync: Database connection closed")
                
                # éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œ
                try:
                    # æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆã—ã¦å®Ÿè¡Œ
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        new_loop.run_until_complete(sync_all_accounts_async())
                    finally:
                        new_loop.close()
                except Exception as e:
                    import traceback
                    print(f"[Meta OAuth] Background sync: ERROR executing async function: {str(e)}")
                    print(f"[Meta OAuth] Background sync: Error details: {traceback.format_exc()}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: asyncio.runã‚’ä½¿ç”¨ï¼ˆæ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆï¼‰
                    try:
                        asyncio.run(sync_all_accounts_async())
                    except Exception as e2:
                        import traceback
                        print(f"[Meta OAuth] Background sync: ERROR with asyncio.run: {str(e2)}")
                        print(f"[Meta OAuth] Background sync: Error details: {traceback.format_exc()}")
            
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¨ã—ã¦è¿½åŠ ï¼ˆåŒæœŸé–¢æ•°ã¨ã—ã¦ï¼‰
            background_tasks.add_task(sync_full_period_background_sync)
            print(f"[Meta OAuth] Background task added for full period sync")
            
            # localhostã®å ´åˆã€https://ã‚’http://ã«å¼·åˆ¶çš„ã«å¤‰æ›ï¼ˆnormalize_localhost_urlé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
            final_frontend_url = normalize_localhost_url(frontend_url)
            print(f"[Meta OAuth] ===== BEFORE REDIRECT URL GENERATION =====")
            print(f"[Meta OAuth] frontend_url (before conversion): {frontend_url}")
            print(f"[Meta OAuth] final_frontend_url (after conversion): {final_frontend_url}")
            if final_frontend_url != frontend_url:
                print(f"[Meta OAuth] Converted HTTPS to HTTP: {frontend_url} -> {final_frontend_url}")
            else:
                print(f"[Meta OAuth] No conversion needed")
            
            account_count = len(accounts)
            if account_count > 1:
                success_url = f"{final_frontend_url}/settings?meta_oauth=success&account_id={account_id}&account_count={account_count}"
            else:
                success_url = f"{final_frontend_url}/settings?meta_oauth=success&account_id={account_id}"
            
            print(f"[Meta OAuth] ===== FINAL REDIRECT URL =====")
            print(f"[Meta OAuth] Final frontend_url: {final_frontend_url}")
            print(f"[Meta OAuth] Success URL: {success_url}")
            print(f"[Meta OAuth] =============================")
            
            # æœ€çµ‚ç¢ºèª: success_urlãŒhttps://localhostã‚’å«ã‚“ã§ã„ãªã„ã“ã¨ã‚’ç¢ºèª
            if 'https://localhost' in success_url or 'https://127.0.0.1' in success_url:
                print(f"[Meta OAuth] âš ï¸ WARNING: Success URL still contains https://localhost! Forcing conversion...")
                success_url = success_url.replace('https://localhost', 'http://localhost')
                success_url = success_url.replace('https://127.0.0.1', 'http://127.0.0.1')
                print(f"[Meta OAuth] Corrected Success URL: {success_url}")
            
            # æœ€çµ‚çš„ãªURLã‚’å†åº¦ç¢ºèª
            print(f"[Meta OAuth] ===== FINAL URL CHECK =====")
            print(f"[Meta OAuth] Final success_url: {success_url}")
            print(f"[Meta OAuth] Contains https://localhost: {'https://localhost' in success_url}")
            print(f"[Meta OAuth] Contains http://localhost: {'http://localhost' in success_url}")
            print(f"[Meta OAuth] ==========================")
            
            # RedirectResponseã‚’æ˜ç¤ºçš„ã«302ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã§ç”Ÿæˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯307ï¼‰
            redirect_response = RedirectResponse(url=success_url, status_code=302)
            
            # RedirectResponseã®URLã‚’å†åº¦ç¢ºèªï¼ˆheaders['location']ã‹ã‚‰å–å¾—ï¼‰
            print(f"[Meta OAuth] ===== REDIRECT RESPONSE CREATED =====")
            print(f"[Meta OAuth] RedirectResponse.status_code: {redirect_response.status_code}")
            print(f"[Meta OAuth] RedirectResponse.headers['location']: {redirect_response.headers.get('location', 'N/A')}")
            print(f"[Meta OAuth] =====================================")
            
            return redirect_response
            
    except httpx.HTTPStatusError as e:
        error_text = e.response.text if hasattr(e.response, 'text') else str(e)
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'Meta APIã‚¨ãƒ©ãƒ¼: {error_text}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    except HTTPException:
        # HTTPExceptionã¯ãã®ã¾ã¾å†ã‚¹ãƒ­ãƒ¼ï¼ˆãŸã ã—ã€ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ï¼‰
        raise
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta OAuth] Error in callback: {str(e)}")
        print(f"[Meta OAuth] Error details: {error_details}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'OAuthèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
            
    except httpx.HTTPStatusError as e:
        error_text = e.response.text if hasattr(e.response, 'text') else str(e)
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'Meta APIã‚¨ãƒ©ãƒ¼: {error_text}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    except HTTPException:
        # HTTPExceptionã¯ãã®ã¾ã¾å†ã‚¹ãƒ­ãƒ¼ï¼ˆãŸã ã—ã€ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ï¼‰
        raise
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta OAuth] Error in callback: {str(e)}")
        print(f"[Meta OAuth] Error details: {error_details}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'OAuthèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
            
    except httpx.HTTPStatusError as e:
        error_text = e.response.text if hasattr(e.response, 'text') else str(e)
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'Meta APIã‚¨ãƒ©ãƒ¼: {error_text}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    except HTTPException:
        # HTTPExceptionã¯ãã®ã¾ã¾å†ã‚¹ãƒ­ãƒ¼ï¼ˆãŸã ã—ã€ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ï¼‰
        raise
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta OAuth] Error in callback: {str(e)}")
        print(f"[Meta OAuth] Error details: {error_details}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'OAuthèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
            
    except httpx.HTTPStatusError as e:
        error_text = e.response.text if hasattr(e.response, 'text') else str(e)
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'Meta APIã‚¨ãƒ©ãƒ¼: {error_text}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)
    except HTTPException:
        # HTTPExceptionã¯ãã®ã¾ã¾å†ã‚¹ãƒ­ãƒ¼ï¼ˆãŸã ã—ã€ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ï¼‰
        raise
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"[Meta OAuth] Error in callback: {str(e)}")
        print(f"[Meta OAuth] Error details: {error_details}")
        normalized_url = normalize_localhost_url(frontend_url)
        error_url = f"{normalized_url}/settings?meta_oauth=error&message={urllib.parse.quote(f'OAuthèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}')}"
        if 'https://localhost' in error_url or 'https://127.0.0.1' in error_url:
            error_url = error_url.replace('https://localhost', 'http://localhost')
            error_url = error_url.replace('https://127.0.0.1', 'http://127.0.0.1')
        return RedirectResponse(url=error_url, status_code=302)


@router.post("/update-unique-reach")
async def update_unique_reach(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    å…¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’Meta APIã‹ã‚‰å–å¾—ã—ã¦DBã«ä¿å­˜
    """
    if not current_user.meta_access_token:
        raise HTTPException(
            status_code=400,
            detail="Metaã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šç”»é¢ã§Metaã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚"
        )
    
    access_token = current_user.meta_access_token
    
    try:
        # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æƒ…å ±ã‚’å–å¾—
        print("[Update Unique Reach] Fetching campaign information from database...")
        campaign_query = text("""
            SELECT 
                campaign_name,
                meta_account_id,
                MIN(date) as start_date,
                MAX(date) as end_date
            FROM campaigns
            WHERE campaign_name IS NOT NULL 
              AND campaign_name != ''
              AND meta_account_id IS NOT NULL
              AND meta_account_id != ''
            GROUP BY campaign_name, meta_account_id
            ORDER BY campaign_name, meta_account_id
        """)
        
        result = db.execute(campaign_query)
        campaign_rows = result.fetchall()
        
        print(f"[Update Unique Reach] Found {len(campaign_rows)} unique campaigns")
        
        if len(campaign_rows) == 0:
            return {
                "success_count": 0,
                "error_count": 0,
                "details": [],
                "message": "æ›´æ–°å¯¾è±¡ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            }
        
        success_count = 0
        error_count = 0
        details = []
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            for row in campaign_rows:
                campaign_name = row[0]
                meta_account_id = row[1]
                start_date = row[2]
                end_date = row[3]
                
                print(f"[Update Unique Reach] Processing: {campaign_name} ({meta_account_id})")
                
                try:
                    # 2a) Meta Graph API ã§ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³IDã‚’æ¤œç´¢
                    # meta_account_idã‹ã‚‰"act_"ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ï¼ˆæ—¢ã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
                    account_id = meta_account_id.replace("act_", "") if meta_account_id.startswith("act_") else meta_account_id
                    
                    campaigns_url = f"https://graph.facebook.com/v18.0/act_{account_id}/campaigns"
                    campaigns_params = {
                        "access_token": access_token,
                        "fields": "id,name",
                        "filtering": json.dumps([{"field": "name", "operator": "EQUAL", "value": campaign_name}]),
                        "limit": 100
                    }
                    
                    print(f"[Update Unique Reach] Searching for campaign: {campaign_name}")
                    campaigns_response = await client.get(campaigns_url, params=campaigns_params)
                    campaigns_response.raise_for_status()
                    campaigns_data = campaigns_response.json()
                    
                    campaign_list = campaigns_data.get('data', [])
                    
                    if len(campaign_list) == 0:
                        error_msg = f"Campaign '{campaign_name}' not found in Meta API"
                        print(f"[Update Unique Reach] âŒ {error_msg}")
                        error_count += 1
                        details.append({
                            "campaign_name": campaign_name,
                            "meta_account_id": meta_account_id,
                            "status": "error",
                            "error": error_msg
                        })
                        continue
                    
                    # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³IDã‚’ä½¿ç”¨
                    campaign_id = campaign_list[0].get('id')
                    found_campaign_name = campaign_list[0].get('name', '')
                    
                    print(f"[Update Unique Reach] Found campaign_id: {campaign_id} (name: {found_campaign_name})")
                    
                    # 2b) æœŸé–“å…¨ä½“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’å–å¾—
                    insights_url = f"https://graph.facebook.com/v18.0/{campaign_id}/insights"
                    time_range_dict = {
                        "since": start_date.strftime("%Y-%m-%d"),
                        "until": end_date.strftime("%Y-%m-%d")
                    }
                    time_range_json = json.dumps(time_range_dict, separators=(',', ':'))
                    
                    insights_params = {
                        "access_token": access_token,
                        "fields": "reach",
                        "time_range": time_range_json
                        # time_incrementã¯æŒ‡å®šã—ãªã„ï¼ˆæœŸé–“å…¨ä½“ã®é›†è¨ˆå€¤ã‚’å–å¾—ï¼‰
                    }
                    
                    print(f"[Update Unique Reach] Fetching unique reach for period: {time_range_json}")
                    insights_response = await client.get(insights_url, params=insights_params)
                    insights_response.raise_for_status()
                    insights_data = insights_response.json()
                    
                    insights_list = insights_data.get('data', [])
                    
                    if len(insights_list) == 0:
                        error_msg = f"No insights data returned for campaign '{campaign_name}'"
                        print(f"[Update Unique Reach] âŒ {error_msg}")
                        error_count += 1
                        details.append({
                            "campaign_name": campaign_name,
                            "meta_account_id": meta_account_id,
                            "status": "error",
                            "error": error_msg
                        })
                        continue
                    
                    # time_incrementãªã—ã®å ´åˆã€æœŸé–“å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã¯1ä»¶ã®ã¿
                    unique_reach = int(insights_list[0].get('reach', 0))
                    
                    print(f"[Update Unique Reach] Meta API unique reach: {unique_reach:,}")
                    
                    # 2c) å–å¾—ã—ãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã® period_unique_reach ã«æ›´æ–°
                    update_query = text("""
                        UPDATE campaigns 
                        SET period_unique_reach = :unique_reach 
                        WHERE campaign_name = :campaign_name 
                          AND meta_account_id = :meta_account_id
                    """)
                    
                    db.execute(update_query, {
                        "unique_reach": unique_reach,
                        "campaign_name": campaign_name,
                        "meta_account_id": meta_account_id
                    })
                    db.commit()
                    
                    # æ›´æ–°ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèª
                    count_query = text("""
                        SELECT COUNT(*) 
                        FROM campaigns 
                        WHERE campaign_name = :campaign_name 
                          AND meta_account_id = :meta_account_id
                    """)
                    count_result = db.execute(count_query, {
                        "campaign_name": campaign_name,
                        "meta_account_id": meta_account_id
                    })
                    updated_count = count_result.scalar()
                    
                    print(f"[Update Unique Reach] âœ… Updated {updated_count} records for '{campaign_name}': period_unique_reach = {unique_reach:,}")
                    
                    success_count += 1
                    details.append({
                        "campaign_name": campaign_name,
                        "meta_account_id": meta_account_id,
                        "status": "success",
                        "unique_reach": unique_reach,
                        "updated_records": updated_count
                    })
                    
                except httpx.HTTPStatusError as e:
                    error_msg = f"Meta API error: {e.response.status_code} - {e.response.text[:200]}"
                    print(f"[Update Unique Reach] âŒ {error_msg}")
                    error_count += 1
                    details.append({
                        "campaign_name": campaign_name,
                        "meta_account_id": meta_account_id,
                        "status": "error",
                        "error": error_msg
                    })
                    continue
                except Exception as e:
                    error_msg = f"Unexpected error: {str(e)}"
                    print(f"[Update Unique Reach] âŒ {error_msg}")
                    import traceback
                    print(f"[Update Unique Reach] Traceback: {traceback.format_exc()}")
                    error_count += 1
                    details.append({
                        "campaign_name": campaign_name,
                        "meta_account_id": meta_account_id,
                        "status": "error",
                        "error": error_msg
                    })
                    continue
        
        return {
            "success_count": success_count,
            "error_count": error_count,
            "total": success_count + error_count,
            "total_campaigns": len(campaign_rows),
            "details": details,
            "message": f"{success_count}/{len(campaign_rows)}ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚"
        }
        
    except Exception as e:
        db.rollback()
        import traceback
        error_details = traceback.format_exc()
        print(f"[Update Unique Reach] CRITICAL ERROR: {str(e)}")
        print(f"[Update Unique Reach] Traceback: {error_details}")
        raise HTTPException(
            status_code=500,
            detail=f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªãƒ¼ãƒæ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}"
        )
