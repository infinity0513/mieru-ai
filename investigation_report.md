# ハイブリッドマーケティング・ハイブリッドマーケティング１ リーチデータ問題調査レポート

## 調査目的
「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」について、以下の問題の原因を特定：
1. 日別のリーチデータがしっかり取得できていない
2. ユニークリーチもしっかりできていない

## 調査結果

### 1. Meta APIからの日次データ取得ロジック

#### 1.1 日次データ取得の設定
- **場所**: `backend/app/routers/meta_api.py` (line 188, 211)
- **設定**: `time_increment=1` が設定されている
- **評価**: ✅ 正しく設定されている

#### 1.2 日次データ取得のリクエスト
```python
relative_url = f"{campaign_id}/insights?fields={campaign_fields}&time_range={time_range_encoded}&time_increment={time_increment}&limit=100"
```
- **評価**: ✅ リクエスト形式は正しい

#### 1.3 潜在的な問題点
- **問題1**: `time_increment=1`が正しく動作しているか確認が必要
  - Meta APIのレスポンスで、複数の日付のデータが返されているか確認が必要
  - ログで「All insights have the same date!」という警告が出ていないか確認が必要（line 869-872）

- **問題2**: ページネーション処理
  - ページネーション処理は実装されている（line 327-341）
  - ただし、すべてのページが正しく取得されているか確認が必要

### 2. ユニークリーチの取得ロジック

#### 2.1 期間別ユニークリーチの取得
- **場所**: `backend/app/routers/meta_api.py` (line 373-507, 675-812)
- **方法**: `time_increment`なしで期間全体の集計データを取得
- **評価**: ✅ 正しい方法

#### 2.2 ユニークリーチのマッピング
- **場所**: `backend/app/routers/meta_api.py` (line 897-911, 1155-1174)
- **方法**: キャンペーン名でマッピング
```python
if (not ad_set_name or ad_set_name == '') and (not ad_name or ad_name == ''):
    period_unique_reach_7days = campaign_period_reach_7days_map.get(campaign_name, 0)
    period_unique_reach_30days = campaign_period_reach_30days_map.get(campaign_name, 0)
    period_unique_reach_all = campaign_period_reach_all_map.get(campaign_name, 0)
```

#### 2.3 潜在的な問題点
- **問題1**: キャンペーン名の一致
  - Meta APIから取得したキャンペーン名と、日次データのキャンペーン名が完全に一致している必要がある
  - キャンペーン名にスペースや特殊文字が含まれている場合、一致しない可能性がある
  - 「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」のキャンペーン名が正確に一致しているか確認が必要

- **問題2**: マッピングのタイミング
  - 期間別ユニークリーチの取得は、日次データの取得の前に行われている（line 373-507）
  - ただし、日次データの保存時にマッピングが正しく行われているか確認が必要

- **問題3**: フォールバック処理
  - `period_unique_reach_all`が0の場合、日次の`reach`をフォールバックとして使用している（line 1172-1174）
  - これは本来の動作ではないが、データが取得できていない場合のフォールバックとして機能している

### 3. データ保存のロジック

#### 3.1 重複チェック
- **場所**: `backend/app/routers/meta_api.py` (line 1142-1146)
- **方法**: `seen_records`セットを使用して重複をチェック
```python
record_key = (campaign_name, ad_set_name, ad_name, campaign_date, account_id)
if record_key in seen_records:
    print(f"[Meta API] WARNING: Duplicate record skipped: ...")
    continue
seen_records.add(record_key)
```
- **評価**: ✅ 重複チェックは実装されている

#### 3.2 データ削除と保存
- **場所**: `backend/app/routers/meta_api.py` (line 828-1232)
- **方法**: 全上書き方式（既存データを削除してから新規作成）
- **評価**: ✅ 正しい方法

#### 3.3 潜在的な問題点
- **問題1**: トランザクションの範囲
  - 削除と保存が同一トランザクションで実行されている（line 1231-1232）
  - ただし、エラーが発生した場合のロールバック処理が正しく動作しているか確認が必要

- **問題2**: データの一貫性
  - キャンペーンレベルのデータに対して、期間別のユニークリーチが正しく設定されているか確認が必要
  - 特に、「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」のデータが正しく保存されているか確認が必要

### 4. フロントエンドのデータ取得とフィルタリング

#### 4.1 データ取得
- **場所**: `frontend/src/services/api.ts` (line 1204-1373)
- **方法**: `level=campaign`パラメータを明示的に指定
- **評価**: ✅ 正しく実装されている

#### 4.2 フィルタリング
- **場所**: `frontend/src/components/Dashboard.tsx` (line 2167-2236)
- **方法**: キャンペーンレベルのデータをフィルタリングしてから日付範囲でフィルタリング
- **評価**: ✅ 正しい順序でフィルタリングされている

#### 4.3 潜在的な問題点
- **問題1**: データの取得範囲
  - 全期間データを取得する際に、すべての日次データが取得されているか確認が必要
  - ページネーション処理が正しく動作しているか確認が必要

- **問題2**: ユニークリーチの計算
  - 期間別のユニークリーチは、データベースから取得した`period_unique_reach_all`を使用している（line 2534-2545）
  - ただし、データベースに正しい値が保存されているか確認が必要

### 5. バックエンドAPIのフィルタリング

#### 5.1 キャンペーンレベルのフィルタリング
- **場所**: `backend/app/routers/campaigns.py` (line 672-714)
- **方法**: `level=campaign`が指定されている場合、`ad_set_name`と`ad_name`が空またはNULLのデータのみを返す
- **評価**: ✅ 正しく実装されている

#### 5.2 潜在的な問題点
- **問題1**: デフォルトの動作
  - `level`が指定されていない場合、デフォルトでキャンペーンレベルのみを返す（line 702-714）
  - ただし、フロントエンドからは`level=campaign`が明示的に指定されているため、問題ない

### 6. データベースの実際のデータ

#### 6.1 確認が必要な項目
1. **日次データの件数**
   - 「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」の日次データが何件保存されているか
   - 期待される日数分のデータが保存されているか

2. **ユニークリーチの値**
   - `period_unique_reach_all`、`period_unique_reach_7days`、`period_unique_reach_30days`の値が正しく保存されているか
   - 同じキャンペーンの異なる日付のレコードで、これらの値が一致しているか

3. **データの重複**
   - 同じキャンペーン名、同じ日付で複数のレコードが存在しないか
   - キャンペーンレベルのデータと広告セット/広告レベルのデータが混在していないか

4. **キャンペーン名の一致**
   - Meta APIから取得したキャンペーン名と、データベースに保存されているキャンペーン名が完全に一致しているか
   - 「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」のキャンペーン名が正確に一致しているか

## 推奨される調査手順

### ステップ1: データベースの実際のデータを確認
```sql
-- ハイブリッドマーケティングの日次データを確認
SELECT 
    campaign_name,
    date,
    reach,
    period_unique_reach_all,
    period_unique_reach_7days,
    period_unique_reach_30days,
    ad_set_name,
    ad_name
FROM campaigns
WHERE campaign_name LIKE '%ハイブリッドマーケティング%'
ORDER BY campaign_name, date;
```

### ステップ2: Meta APIからのデータ取得ログを確認
- Meta API同期処理のログで、以下の点を確認：
  1. `time_increment=1`が正しく設定されているか
  2. 日次データが複数の日付で返されているか（「All insights have the same date!」という警告が出ていないか）
  3. ページネーション処理が正しく動作しているか
  4. 「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」のキャンペーン名が正確に取得されているか

### ステップ3: ユニークリーチの取得ログを確認
- 期間別ユニークリーチ取得のログで、以下の点を確認：
  1. 「ハイブリッドマーケティング」と「ハイブリッドマーケティング１」のユニークリーチが正しく取得されているか
  2. 取得したユニークリーチの値が正しいか
  3. マッピングが正しく行われているか

### ステップ4: フロントエンドのデータ取得ログを確認
- ブラウザのコンソールログで、以下の点を確認：
  1. データ取得時に`level=campaign`が正しく指定されているか
  2. 取得したデータの件数が期待通りか
  3. フィルタリングが正しく動作しているか
  4. ユニークリーチの計算が正しく行われているか

### ステップ5: デバッグAPIエンドポイントを使用
- `/api/campaigns/debug/reach-comparison?campaign_name=ハイブリッドマーケティング`
- `/api/campaigns/debug/duplicate-check?campaign_name=ハイブリッドマーケティング`
- これらのエンドポイントを使用して、データの不整合を確認

## 考えられる原因

### 原因1: Meta APIからの日次データ取得が不完全
- `time_increment=1`が正しく動作していない
- ページネーション処理が不完全
- 日付範囲の指定が正しくない

### 原因2: キャンペーン名の不一致
- Meta APIから取得したキャンペーン名と、データベースに保存されているキャンペーン名が一致しない
- キャンペーン名にスペースや特殊文字が含まれている場合、一致しない可能性がある

### 原因3: ユニークリーチのマッピングエラー
- 期間別ユニークリーチの取得が失敗している
- マッピングが正しく行われていない
- キャンペーン名の不一致により、マッピングが失敗している

### 原因4: データの重複や不整合
- 同じキャンペーン名、同じ日付で複数のレコードが存在する
- キャンペーンレベルのデータと広告セット/広告レベルのデータが混在している
- データの削除と保存のタイミングがずれている

### 原因5: フロントエンドのフィルタリングエラー
- データ取得時に正しいフィルタが適用されていない
- フィルタリングの順序が正しくない
- ユニークリーチの計算ロジックに問題がある

## 次のステップ

1. **データベースの実際のデータを確認**
   - SQLクエリを実行して、実際のデータを確認
   - 日次データの件数、ユニークリーチの値、データの重複を確認

2. **Meta API同期処理のログを確認**
   - 日次データ取得のログを確認
   - ユニークリーチ取得のログを確認
   - エラーや警告がないか確認

3. **デバッグAPIエンドポイントを使用**
   - `/api/campaigns/debug/reach-comparison`を使用して、データの不整合を確認
   - `/api/campaigns/debug/duplicate-check`を使用して、データの重複を確認

4. **フロントエンドのログを確認**
   - ブラウザのコンソールログを確認
   - データ取得、フィルタリング、計算の各ステップで問題がないか確認

5. **問題が特定できたら、修正を実施**
   - 原因が特定できたら、適切な修正を実施
   - 修正後、再度データを確認して問題が解決したか確認

